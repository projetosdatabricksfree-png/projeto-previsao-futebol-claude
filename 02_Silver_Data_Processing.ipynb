{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fcda7225-93d8-4d81-a77c-624edd54e494",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CONFIGURAÇÕES E IMPORTS\n",
    "# ==============================================================================\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType\n",
    "\n",
    "# Configurar o uso do nosso catálogo e dos schemas\n",
    "spark.sql(\"USE CATALOG previsao_brasileirao\")\n",
    "\n",
    "# Definir os schemas de origem (Bronze) e destino (Silver)\n",
    "bronze_schema = \"bronze\"\n",
    "silver_schema = \"silver\"\n",
    "\n",
    "print(f\"Lendo dados de: {bronze_schema}\")\n",
    "print(f\"Salvando dados em: {silver_schema}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c3631aa-a090-4d2b-8a67-98a9417a2b3d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# PASSO 1: LIMPAR E ESTRUTURAR A TABELA DE PARTIDAS\n",
    "# ==============================================================================\n",
    "print(\"Iniciando processamento da tabela de partidas...\")\n",
    "\n",
    "# Ler a tabela bruta da camada Bronze\n",
    "df_partidas_bronze = spark.table(f\"{bronze_schema}.partidas_raw\")\n",
    "\n",
    "df_partidas_silver = (\n",
    "    df_partidas_bronze\n",
    "    # Renomear colunas para um padrão mais claro\n",
    "    .withColumnRenamed(\"clube_casa_id\", \"mandante_id\")\n",
    "    .withColumnRenamed(\"clube_visitante_id\", \"visitante_id\")\n",
    "    .withColumnRenamed(\"placar_oficial_mandante\", \"mandante_placar\")\n",
    "    .withColumnRenamed(\"placar_oficial_visitante\", \"visitante_placar\")\n",
    "    .withColumnRenamed(\"partida_data\", \"data_partida\")\n",
    "    \n",
    "    # Converter a data da partida para o formato Timestamp\n",
    "    .withColumn(\"data_partida\", F.to_timestamp(\"data_partida\"))\n",
    "    \n",
    "    # Criar a variável alvo (target) para o modelo de classificação\n",
    "    .withColumn(\"resultado\",\n",
    "        F.when(F.col(\"mandante_placar\") > F.col(\"visitante_placar\"), \"VITORIA_MANDANTE\")\n",
    "         .when(F.col(\"mandante_placar\") < F.col(\"visitante_placar\"), \"VITORIA_VISITANTE\")\n",
    "         .when(F.col(\"mandante_placar\") == F.col(\"visitante_placar\"), \"EMPATE\")\n",
    "         .otherwise(None) # Para partidas futuras que não têm placar\n",
    "    )\n",
    "    # Selecionar apenas as colunas relevantes para a camada Silver\n",
    "    .select(\n",
    "        \"partida_id\",\n",
    "        \"rodada\",\n",
    "        \"data_partida\",\n",
    "        \"mandante_id\",\n",
    "        \"visitante_id\",\n",
    "        \"mandante_placar\",\n",
    "        \"visitante_placar\",\n",
    "        \"resultado\",\n",
    "        \"valida\"\n",
    "    )\n",
    "    # Filtrar apenas as partidas válidas que já aconteceram (têm resultado)\n",
    "    .filter(\"resultado IS NOT NULL AND valida = true\")\n",
    ")\n",
    "\n",
    "# Salvar a tabela limpa na camada Silver\n",
    "df_partidas_silver.write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .format(\"delta\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(f\"{silver_schema}.partidas\")\n",
    "\n",
    "print(f\"✅ Tabela 'partidas' salva com sucesso na camada Silver.\")\n",
    "display(spark.table(f\"{silver_schema}.partidas\").orderBy(F.desc(\"data_partida\")).limit(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "50e9af6a-ef59-4e00-a24f-9f25bb481c3c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# PASSO 2: DESEMPACOTAR SCOUTS E CRIAR ESTATÍSTICAS POR JOGADOR\n",
    "# ==============================================================================\n",
    "print(\"Iniciando processamento da tabela de pontuações e scouts...\")\n",
    "\n",
    "# Ler a tabela bruta\n",
    "df_pontuacoes_bronze = spark.table(f\"{bronze_schema}.pontuacoes_historico_raw\")\n",
    "\n",
    "# --- AJUSTE APLICADO AQUI ---\n",
    "# A coluna 'scout' já é uma estrutura (MapType ou StructType), não uma string JSON.\n",
    "# Em vez de usar from_json, vamos selecionar os elementos diretamente.\n",
    "\n",
    "# Lista de todos os scouts possíveis para selecionar\n",
    "lista_de_scouts = [\"A\", \"CA\", \"CV\", \"DD\", \"DP\", \"DS\", \"FC\", \"FD\", \"FF\", \"FS\", \"G\", \"GC\", \"GS\", \"I\", \"PE\", \"RB\", \"SG\"]\n",
    "# Criar a lista de colunas para o select dinamicamente\n",
    "select_scouts = [F.col(f\"scout.{scout}\").alias(scout) for scout in lista_de_scouts]\n",
    "\n",
    "df_stats_silver = (\n",
    "    df_pontuacoes_bronze\n",
    "    .select(\n",
    "        \"atleta_id\",\n",
    "        \"rodada_id\",\n",
    "        \"clube_id\",\n",
    "        \"pontos_num\",\n",
    "        *select_scouts # O asterisco desempacota a lista de colunas aqui\n",
    "    )\n",
    "    # Substituir quaisquer valores nulos nos scouts (para jogadores que não tiveram o scout) por 0\n",
    "    .na.fill(0, subset=lista_de_scouts)\n",
    ")\n",
    "# --- FIM DO AJUSTE ---\n",
    "\n",
    "# Juntar com a tabela de partidas para obter o partida_id\n",
    "df_partidas_silver_ref = spark.table(f\"{silver_schema}.partidas\").select(\"rodada\", \"mandante_id\", \"visitante_id\", \"partida_id\")\n",
    "\n",
    "# Criar duas visões das partidas para juntar mandantes e visitantes\n",
    "partidas_mandante = df_partidas_silver_ref.select(F.col(\"rodada\"), F.col(\"mandante_id\").alias(\"clube_id\"), F.col(\"partida_id\"))\n",
    "partidas_visitante = df_partidas_silver_ref.select(F.col(\"rodada\"), F.col(\"visitante_id\").alias(\"clube_id\"), F.col(\"partida_id\"))\n",
    "partidas_clubes = partidas_mandante.union(partidas_visitante)\n",
    "\n",
    "# Juntar as estatísticas com as partidas para ter o contexto completo\n",
    "# Adicionado alias para evitar colunas ambíguas no join\n",
    "df_stats_silver_aliased = df_stats_silver.alias(\"stats\")\n",
    "partidas_clubes_aliased = partidas_clubes.alias(\"partidas\")\n",
    "\n",
    "df_estatisticas_final = df_stats_silver_aliased.join(\n",
    "    partidas_clubes_aliased,\n",
    "    (F.col(\"stats.rodada_id\") == F.col(\"partidas.rodada\")) & (F.col(\"stats.clube_id\") == F.col(\"partidas.clube_id\")),\n",
    "    \"inner\"\n",
    ").select(\n",
    "    \"partidas.partida_id\",\n",
    "    \"stats.rodada_id\",\n",
    "    \"stats.atleta_id\",\n",
    "    \"stats.clube_id\",\n",
    "    \"stats.pontos_num\",\n",
    "    *lista_de_scouts # Reutiliza a lista para selecionar todas as colunas de scout\n",
    ")\n",
    "\n",
    "\n",
    "# Salvar a tabela final na camada Silver\n",
    "df_estatisticas_final.write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .format(\"delta\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(f\"{silver_schema}.estatisticas_jogador_partida\")\n",
    "\n",
    "print(f\"✅ Tabela 'estatisticas_jogador_partida' salva com sucesso na camada Silver.\")\n",
    "display(spark.table(f\"{silver_schema}.estatisticas_jogador_partida\").limit(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4836b85f-abf1-4803-9a45-303535291a62",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# PASSO 3: LIMPAR E PADRONIZAR A TABELA DE CLUBES\n",
    "# ==============================================================================\n",
    "print(\"Iniciando processamento da tabela de clubes...\")\n",
    "\n",
    "df_clubes_silver = (\n",
    "    spark.table(f\"{bronze_schema}.clubes_info_raw\")\n",
    "    .withColumnRenamed(\"id\", \"clube_id\")\n",
    "    .withColumnRenamed(\"nome_fantasia\", \"nome_completo\")\n",
    "    .select(\"clube_id\", \"nome\", \"abreviacao\", \"nome_completo\")\n",
    ")\n",
    "\n",
    "df_clubes_silver.write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .format(\"delta\") \\\n",
    "    .saveAsTable(f\"{silver_schema}.clubes\")\n",
    "\n",
    "print(f\"✅ Tabela 'clubes' salva com sucesso na camada Silver.\")\n",
    "display(spark.table(f\"{silver_schema}.clubes\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c7dea2f4-2ed8-4b72-b17a-cc805807f23a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# VALIDAÇÃO DA CAMADA SILVER\n",
    "# ==============================================================================\n",
    "print(\"--- Sumário da Camada Silver ---\")\n",
    "for table_name in [\"partidas\", \"estatisticas_jogador_partida\", \"clubes\"]:\n",
    "    print(f\"\\nTabela: {silver_schema}.{table_name}\")\n",
    "    df = spark.table(f\"{silver_schema}.{table_name}\")\n",
    "    print(f\"  - Registros: {df.count():,}\")\n",
    "    print(f\"  - Colunas: {len(df.columns)}\")\n",
    "    df.printSchema()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "02_Silver_Data_Processing",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
