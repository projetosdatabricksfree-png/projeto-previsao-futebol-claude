{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad341b69-9bdb-4eda-89d6-b4526a0a0cff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CONFIGURA√á√ïES E IMPORTS\n",
    "# ==============================================================================\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from pyspark.sql import functions as F\n",
    "import json\n",
    "\n",
    "# Configurar cat√°logo e schema (padr√£o Unity Catalog)\n",
    "spark.sql(\"USE CATALOG previsao_brasileirao\")\n",
    "spark.sql(\"USE SCHEMA bronze\")\n",
    "\n",
    "# Configura√ß√µes de logging\n",
    "print(f\"=\" * 80)\n",
    "print(f\"INICIANDO INGEST√ÉO DA CAMADA BRONZE\")\n",
    "print(f\"Data/Hora: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Cat√°logo: {spark.catalog.currentCatalog()}\")\n",
    "print(f\"Schema: {spark.catalog.currentDatabase()}\")\n",
    "print(f\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd38874e-7631-4462-9055-59bedf3ba108",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# FUN√á√ïES AUXILIARES PARA CHAMADAS √Ä API\n",
    "# ==============================================================================\n",
    "\n",
    "def fazer_requisicao_api(url, timeout=30, retries=3):\n",
    "    \"\"\"\n",
    "    Fun√ß√£o robusta para fazer requisi√ß√µes HTTP com retry logic\n",
    "    \"\"\"\n",
    "    for tentativa in range(retries):\n",
    "        try:\n",
    "            print(f\"  Tentativa {tentativa + 1}/{retries} para {url}\")\n",
    "            response = requests.get(url, timeout=timeout)\n",
    "            response.raise_for_status() # Lan√ßa um erro para status codes HTTP 4xx/5xx\n",
    "            return response.json()\n",
    "        except requests.exceptions.Timeout:\n",
    "            print(f\"  ‚ö†Ô∏è  Timeout na tentativa {tentativa + 1}\")\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"  ‚ö†Ô∏è  Erro na tentativa {tentativa + 1}: {e}\")\n",
    "        \n",
    "        if tentativa < retries - 1:\n",
    "            import time\n",
    "            time.sleep(2 ** tentativa) # Exponential backoff\n",
    "    \n",
    "    raise Exception(f\"Falha ap√≥s {retries} tentativas para {url}\")\n",
    "\n",
    "def adicionar_metadata_ingestao(df):\n",
    "    \"\"\"\n",
    "    Adiciona colunas de metadados de ingest√£o a um DataFrame Spark\n",
    "    \"\"\"\n",
    "    return df.withColumn(\"data_ingestao\", F.current_timestamp()) \\\n",
    "             .withColumn(\"fonte_dados\", F.lit(\"API_Cartola_FC\"))\n",
    "\n",
    "print(\"‚úÖ Fun√ß√µes auxiliares carregadas com sucesso\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71eca2c7-6bb5-443c-b701-fde19555759a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# INGEST√ÉO 1: DADOS DAS RODADAS E PARTIDAS (VERS√ÉO FINAL E OTIMIZADA)\n",
    "# ==============================================================================\n",
    "print(\"\\n[1/4] Iniciando ingest√£o de dados de TODAS as rodadas dispon√≠veis...\")\n",
    "\n",
    "NOME_TABELA_PARTIDAS = \"previsao_brasileirao.bronze.partidas_raw\"\n",
    "TOTAL_RODADAS_CAMPEONATO = 38\n",
    "RODADAS_PARA_BUSCAR = TOTAL_RODADAS_CAMPEONATO + 5 \n",
    "\n",
    "try:\n",
    "    todas_partidas = []\n",
    "    # --- AJUSTE: Contador para parada inteligente ---\n",
    "    rodadas_vazias_consecutivas = 0\n",
    "\n",
    "    for rodada in range(1, RODADAS_PARA_BUSCAR + 1):\n",
    "        try:\n",
    "            url_rodada = f\"https://api.cartolafc.globo.com/partidas/{rodada}\"\n",
    "            dados_rodada = fazer_requisicao_api(url_rodada)\n",
    "            \n",
    "            if 'partidas' in dados_rodada and dados_rodada['partidas']:\n",
    "                for partida in dados_rodada['partidas']:\n",
    "                    partida['rodada'] = rodada\n",
    "                \n",
    "                todas_partidas.extend(dados_rodada['partidas'])\n",
    "                print(f\"  ‚úÖ Rodada {rodada}: {len(dados_rodada['partidas'])} partidas encontradas.\")\n",
    "                # Se encontramos dados, zeramos o contador de rodadas vazias\n",
    "                rodadas_vazias_consecutivas = 0\n",
    "            else:\n",
    "                print(f\"  üü° Rodada {rodada}: Nenhuma partida encontrada.\")\n",
    "                rodadas_vazias_consecutivas += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ö†Ô∏è  Rodada {rodada} n√£o dispon√≠vel ou com erro: {e}\")\n",
    "            rodadas_vazias_consecutivas += 1\n",
    "        \n",
    "        # --- AJUSTE: Condi√ß√£o de parada ---\n",
    "        # Se n√£o encontrarmos dados por 3 rodadas seguidas, paramos o loop.\n",
    "        if rodadas_vazias_consecutivas >= 3:\n",
    "            print(\"\\n  ‚ÑπÔ∏è  Nenhuma partida encontrada por 3 rodadas consecutivas. Encerrando busca antecipadamente.\")\n",
    "            break\n",
    "            \n",
    "    if todas_partidas:\n",
    "        df_partidas_spark = spark.createDataFrame(todas_partidas)\n",
    "        \n",
    "        df_partidas_spark.write \\\n",
    "            .format(\"delta\") \\\n",
    "            .mode(\"overwrite\") \\\n",
    "            .option(\"overwriteSchema\", \"true\") \\\n",
    "            .saveAsTable(NOME_TABELA_PARTIDAS)\n",
    "        \n",
    "        print(f\"\\n‚úÖ SUCESSO! {df_partidas_spark.count()} registros de partidas salvos em '{NOME_TABELA_PARTIDAS}'\")\n",
    "    else:\n",
    "        print(\"‚ùå ERRO CR√çTICO: Nenhuma partida foi encontrada em nenhuma rodada.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå ERRO GERAL na ingest√£o de partidas: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3fea4809-c60e-456b-a4c5-bd4bc9cd82ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# INGEST√ÉO 2: STATUS E ESTAT√çSTICAS DOS JOGADORES\n",
    "# ==============================================================================\n",
    "print(\"\\n[2/4] Iniciando ingest√£o de status dos jogadores...\")\n",
    "\n",
    "# --- AJUSTE APLICADO AQUI: DEFINI√á√ÉO EXPL√çCITA DO SCHEMA ---\n",
    "from pyspark.sql.types import StructType, StructField, LongType, StringType, DoubleType\n",
    "\n",
    "# Definimos a estrutura exata dos dados, tratando campos num√©ricos que podem\n",
    "# ter decimais como DoubleType para evitar conflitos.\n",
    "schema_jogadores = StructType([\n",
    "    StructField(\"atleta_id\", LongType(), True),\n",
    "    StructField(\"apelido\", StringType(), True),\n",
    "    StructField(\"clube_id\", LongType(), True),\n",
    "    StructField(\"foto\", StringType(), True),\n",
    "    StructField(\"jogos_num\", LongType(), True),\n",
    "    StructField(\"media_num\", DoubleType(), True),\n",
    "    StructField(\"minimo_para_valorizar\", DoubleType(), True),\n",
    "    StructField(\"nome\", StringType(), True),\n",
    "    StructField(\"pontos_num\", DoubleType(), True),\n",
    "    StructField(\"posicao_id\", LongType(), True),\n",
    "    StructField(\"preco_num\", DoubleType(), True),\n",
    "    StructField(\"rodada_id\", LongType(), True),\n",
    "    StructField(\"scout\", StringType(), True), # O scout vem como um objeto, mas o salvamos como JSON string\n",
    "    StructField(\"slug\", StringType(), True),\n",
    "    StructField(\"status_id\", LongType(), True),\n",
    "    StructField(\"variacao_num\", DoubleType(), True),\n",
    "    StructField(\"gato_mestre\", StructType([ # Campo aninhado\n",
    "        StructField(\"epoca_maior_pontuador\", LongType(), True),\n",
    "        StructField(\"gato_mestre\", StringType(), True),\n",
    "        StructField(\"media_pontos_mandante\", DoubleType(), True),\n",
    "        StructField(\"media_pontos_visitante\", DoubleType(), True),\n",
    "        StructField(\"media_pontos_geral\", DoubleType(), True)\n",
    "    ]), True)\n",
    "])\n",
    "# --- FIM DO AJUSTE ---\n",
    "\n",
    "URL_MERCADO = \"https://api.cartolafc.globo.com/atletas/mercado\"\n",
    "NOME_TABELA_JOGADORES = \"previsao_brasileirao.bronze.jogadores_status_raw\"\n",
    "\n",
    "try:\n",
    "    dados_mercado = fazer_requisicao_api(URL_MERCADO)\n",
    "    \n",
    "    rodada_atual_jogadores = dados_mercado.get('rodada_atual')\n",
    "    atletas = dados_mercado.get('atletas', [])\n",
    "    for atleta in atletas:\n",
    "        atleta['rodada_id'] = rodada_atual_jogadores\n",
    "        # Garantir que o scout seja uma string JSON para compatibilidade com o schema\n",
    "        if 'scout' in atleta and atleta['scout'] is not None:\n",
    "            atleta['scout'] = json.dumps(atleta['scout'])\n",
    "        else:\n",
    "            atleta['scout'] = None\n",
    "\n",
    "    if atletas:\n",
    "        # Usando o schema expl√≠cito ao criar o DataFrame\n",
    "        df_jogadores_spark = spark.createDataFrame(atletas, schema=schema_jogadores)\n",
    "        \n",
    "        df_jogadores_spark = adicionar_metadata_ingestao(df_jogadores_spark)\n",
    "        \n",
    "        df_jogadores_spark.write \\\n",
    "            .format(\"delta\") \\\n",
    "            .mode(\"overwrite\") \\\n",
    "            .option(\"overwriteSchema\", \"true\") \\\n",
    "            .saveAsTable(NOME_TABELA_JOGADORES)\n",
    "        \n",
    "        print(f\"\\n‚úÖ SUCESSO! {len(atletas)} jogadores salvos em '{NOME_TABELA_JOGADORES}'\")\n",
    "        display(df_jogadores_spark.limit(5))\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Nenhum jogador encontrado na API do mercado.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå ERRO na ingest√£o de jogadores: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e0a50ad-a6b6-41f8-98c1-53dd04f18dc0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# INGEST√ÉO 3: INFORMA√á√ïES DOS CLUBES\n",
    "# ==============================================================================\n",
    "print(\"\\n[3/4] Iniciando ingest√£o de informa√ß√µes dos clubes...\")\n",
    "\n",
    "# --- AJUSTE APLICADO AQUI: DEFINI√á√ÉO EXPL√çCITA DO SCHEMA ---\n",
    "from pyspark.sql.types import StructType, StructField, LongType, StringType, MapType\n",
    "\n",
    "# Definimos a estrutura dos dados dos clubes.\n",
    "# O campo 'escudos' √© um objeto JSON (key-value), ent√£o usamos MapType.\n",
    "schema_clubes = StructType([\n",
    "    StructField(\"id\", LongType(), True),\n",
    "    StructField(\"nome\", StringType(), True),\n",
    "    StructField(\"abreviacao\", StringType(), True),\n",
    "    StructField(\"slug\", StringType(), True),\n",
    "    StructField(\"escudos\", MapType(StringType(), StringType()), True),\n",
    "    StructField(\"nome_fantasia\", StringType(), True)\n",
    "])\n",
    "# --- FIM DO AJUSTE ---\n",
    "\n",
    "URL_CLUBES = \"https://api.cartolafc.globo.com/clubes\"\n",
    "NOME_TABELA_CLUBES = \"previsao_brasileirao.bronze.clubes_info_raw\"\n",
    "\n",
    "try:\n",
    "    dados_clubes = fazer_requisicao_api(URL_CLUBES)\n",
    "    \n",
    "    # A API retorna um dicion√°rio, convertemos para uma lista de objetos\n",
    "    lista_clubes = [clube for clube_id, clube in dados_clubes.items()]\n",
    "    \n",
    "    if lista_clubes:\n",
    "        # --- AJUSTE APLICADO AQUI ---\n",
    "        # Usando createDataFrame com o schema expl√≠cito, que √© compat√≠vel com Serverless\n",
    "        df_clubes_spark = spark.createDataFrame(lista_clubes, schema=schema_clubes)\n",
    "        # --- FIM DO AJUSTE ---\n",
    "        \n",
    "        df_clubes_spark = adicionar_metadata_ingestao(df_clubes_spark)\n",
    "        \n",
    "        df_clubes_spark.write \\\n",
    "            .format(\"delta\") \\\n",
    "            .mode(\"overwrite\") \\\n",
    "            .option(\"overwriteSchema\", \"true\") \\\n",
    "            .saveAsTable(NOME_TABELA_CLUBES)\n",
    "        \n",
    "        print(f\"\\n‚úÖ SUCESSO! {len(lista_clubes)} clubes salvos em '{NOME_TABELA_CLUBES}'\")\n",
    "        display(df_clubes_spark)\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå ERRO na ingest√£o de clubes: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea6f9186-8338-4a07-8075-12e29b59d6fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# INGEST√ÉO 4: PONTUA√á√ïES DOS ATLETAS POR RODADA (HIST√ìRICO)\n",
    "# ==============================================================================\n",
    "print(\"\\n[4/4] Iniciando ingest√£o de pontua√ß√µes hist√≥ricas...\")\n",
    "\n",
    "# --- AJUSTE APLICADO: DEFINI√á√ÉO EXPL√çCITA DO SCHEMA ---\n",
    "from pyspark.sql.types import StructType, StructField, LongType, StringType, DoubleType, MapType\n",
    "\n",
    "# Definimos a estrutura dos dados de pontua√ß√£o para evitar erros de tipo\n",
    "schema_pontuacoes = StructType([\n",
    "    StructField(\"rodada_id\", LongType(), True),\n",
    "    StructField(\"atleta_id\", LongType(), True),\n",
    "    StructField(\"apelido\", StringType(), True),\n",
    "    StructField(\"clube_id\", LongType(), True),\n",
    "    StructField(\"posicao_id\", LongType(), True),\n",
    "    StructField(\"pontos_num\", DoubleType(), True),\n",
    "    StructField(\"preco_num\", DoubleType(), True),\n",
    "    StructField(\"variacao_num\", DoubleType(), True),\n",
    "    StructField(\"scout\", MapType(StringType(), LongType()), True)\n",
    "])\n",
    "# --- FIM DO AJUSTE ---\n",
    "\n",
    "\n",
    "URL_MERCADO = \"https://api.cartolafc.globo.com/atletas/mercado\"\n",
    "NOME_TABELA_PONTUACOES = \"previsao_brasileirao.bronze.pontuacoes_historico_raw\"\n",
    "\n",
    "try:\n",
    "    # --- AJUSTE APLICADO: LIDANDO COM MERCADO FECHADO ---\n",
    "    # Quando o mercado do Cartola est√° fechado, a API n√£o retorna a 'rodada_atual'.\n",
    "    # Para fins de desenvolvimento, vamos definir um valor fixo.\n",
    "    # Em um ambiente de produ√ß√£o, voc√™ poderia verificar o status do mercado antes de prosseguir.\n",
    "    \n",
    "    # Linha original (descomente para usar em produ√ß√£o quando o mercado estiver aberto)\n",
    "    # dados_mercado_pontos = fazer_requisicao_api(URL_MERCADO)\n",
    "    # rodada_atual = dados_mercado_pontos.get('rodada_atual')\n",
    "    \n",
    "    # Linha para desenvolvimento (define a rodada 10 como a \"atual\" para buscar o hist√≥rico)\n",
    "    rodada_atual = 10 \n",
    "    \n",
    "    if not rodada_atual:\n",
    "        raise ValueError(\"N√£o foi poss√≠vel obter a rodada atual da API do mercado.\")\n",
    "    print(f\"  ‚ÑπÔ∏è  Rodada atual para busca de hist√≥rico (definida manualmente): {rodada_atual}\")\n",
    "    # --- FIM DO AJUSTE ---\n",
    "\n",
    "    todas_pontuacoes = []\n",
    "    # Busca das √∫ltimas 10 rodadas (ou desde a 1) at√© a rodada atual\n",
    "    for rodada in range(max(1, rodada_atual - 10), rodada_atual + 1):\n",
    "        try:\n",
    "            url_pontos = f\"https://api.cartolafc.globo.com/atletas/pontuados/{rodada}\"\n",
    "            dados_pontos = fazer_requisicao_api(url_pontos)\n",
    "            \n",
    "            if 'atletas' in dados_pontos:\n",
    "                for atleta_id, atleta_dados in dados_pontos['atletas'].items():\n",
    "                    atleta_dados['rodada_id'] = rodada\n",
    "                    atleta_dados['atleta_id'] = int(atleta_id)\n",
    "                    todas_pontuacoes.append(atleta_dados)\n",
    "                print(f\"  ‚úÖ Rodada {rodada}: {len(dados_pontos['atletas'])} pontua√ß√µes\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ö†Ô∏è  Dados da rodada {rodada} n√£o dispon√≠veis ou com erro: {e}\")\n",
    "            continue\n",
    "    \n",
    "    if todas_pontuacoes:\n",
    "        # --- AJUSTE APLICADO: Usando createDataFrame (compat√≠vel com Serverless) ---\n",
    "        df_pontos_spark = spark.createDataFrame(todas_pontuacoes, schema=schema_pontuacoes)\n",
    "        \n",
    "        df_pontos_spark = adicionar_metadata_ingestao(df_pontos_spark)\n",
    "        \n",
    "        df_pontos_spark.write \\\n",
    "            .format(\"delta\") \\\n",
    "            .mode(\"overwrite\") \\\n",
    "            .option(\"overwriteSchema\", \"true\") \\\n",
    "            .saveAsTable(NOME_TABELA_PONTUACOES)\n",
    "        \n",
    "        print(f\"\\n‚úÖ SUCESSO! {len(todas_pontuacoes)} registros de pontua√ß√µes salvos em '{NOME_TABELA_PONTUACOES}'\")\n",
    "        display(df_pontos_spark.limit(5))\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  Nenhuma pontua√ß√£o hist√≥rica encontrada\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå ERRO na ingest√£o de pontua√ß√µes: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85da16e4-7350-4b84-98d6-4f5da80142b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# VALIDA√á√ÉO E SUM√ÅRIO DA INGEST√ÉO\n",
    "# ==============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SUM√ÅRIO DA INGEST√ÉO - CAMADA BRONZE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "tabelas_bronze = spark.sql(f\"SHOW TABLES IN previsao_brasileirao.bronze\").collect()\n",
    "\n",
    "if not tabelas_bronze:\n",
    "    print(\"Nenhuma tabela encontrada no schema 'previsao_brasileirao.bronze'.\")\n",
    "else:\n",
    "    for tabela in tabelas_bronze:\n",
    "        nome_tabela_completo = f\"previsao_brasileirao.bronze.{tabela['tableName']}\"\n",
    "        try:\n",
    "            df_validacao = spark.table(nome_tabela_completo)\n",
    "            count = df_validacao.count()\n",
    "            \n",
    "            print(f\"\\nüìä Tabela: {nome_tabela_completo}\")\n",
    "            print(f\"   Registros: {count:,}\")\n",
    "            print(f\"   Colunas: {len(df_validacao.columns)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\n‚ùå Erro ao validar a tabela {nome_tabela_completo}: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚úÖ VALIDA√á√ÉO DA CAMADA BRONZE CONCLU√çDA!\")\n",
    "print(f\"Data/Hora: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31463385-ebae-497b-b6ef-961025631d14",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# C√âLULA DE DIAGN√ìSTICO\n",
    "import requests\n",
    "import json\n",
    "\n",
    "try:\n",
    "    # Este √© o endpoint mais confi√°vel para saber o status real do mercado\n",
    "    status_url = \"https://api.cartolafc.globo.com/mercado/status\"\n",
    "    response = requests.get(status_url)\n",
    "    response.raise_for_status()\n",
    "    dados_status = response.json()\n",
    "\n",
    "    print(\"--- Diagn√≥stico da API do Cartola FC ---\")\n",
    "    print(f\"Status do Mercado: {dados_status.get('status_mercado')} (1=Aberto, 2=Fechado, 3=Em atualiza√ß√£o, 4=Processando)\")\n",
    "    print(f\"Rodada Atual segundo a API: {dados_status.get('rodada_atual')}\")\n",
    "    print(f\"Fechamento do Mercado: {dados_status.get('fechamento', {}).get('dia')}/{dados_status.get('fechamento', {}).get('mes')} √†s {dados_status.get('fechamento', {}).get('hora')}:{dados_status.get('fechamento', {}).get('minuto')}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao consultar a API de status: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "083bfa17-a9eb-4083-ad56-e1bb43820076",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# C√âLULA DE DIAGN√ìSTICO FINAL\n",
    "import requests\n",
    "\n",
    "print(\"--- Verificando o conte√∫do real das rodadas na API ---\")\n",
    "\n",
    "# Rodada ATUAL (deve funcionar)\n",
    "url_rodada_29 = \"https://api.cartolafc.globo.com/partidas/29\"\n",
    "try:\n",
    "    dados_29 = requests.get(url_rodada_29).json()\n",
    "    num_partidas_29 = len(dados_29.get('partidas', []))\n",
    "    print(f\"‚úÖ Rodada 29: Encontradas {num_partidas_29} partidas.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro ao buscar Rodada 29: {e}\")\n",
    "\n",
    "# Rodada FUTURA (provavelmente vai falhar ou vir vazia)\n",
    "url_rodada_30 = \"https://api.cartolafc.globo.com/partidas/30\"\n",
    "try:\n",
    "    dados_30 = requests.get(url_rodada_30).json()\n",
    "    num_partidas_30 = len(dados_30.get('partidas', []))\n",
    "    print(f\"‚úÖ Rodada 30: Encontradas {num_partidas_30} partidas.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro ao buscar Rodada 30: {e}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "01_Bronze_Ingestao",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
