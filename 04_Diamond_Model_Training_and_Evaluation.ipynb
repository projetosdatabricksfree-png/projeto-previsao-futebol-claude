{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f44f0940-2047-4e73-abda-4a9e2dbb2d70",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CONFIGURAÇÕES E IMPORTS\n",
    "# ==============================================================================\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier\n",
    "# Para o XGBoost, a instalação e importação pode variar no Databricks\n",
    "# Vamos usar o GBTClassifier como um substituto poderoso e nativo do Spark\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.sql import functions as F\n",
    "import pandas as pd\n",
    "\n",
    "# Configurar o uso do nosso catálogo e dos schemas\n",
    "spark.sql(\"USE CATALOG previsao_brasileirao\")\n",
    "gold_schema = \"gold\"\n",
    "diamond_schema = \"diamond\"\n",
    "\n",
    "print(f\"Lendo dados de: {gold_schema}\")\n",
    "print(f\"Salvando modelos e métricas em: {diamond_schema}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d557b8cf-500a-4708-b754-30451951897d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# PASSO 1: CARREGAR A FEATURE STORE E DIVIDIR EM TREINO/TESTE\n",
    "# ==============================================================================\n",
    "print(\"Carregando feature_store e dividindo os dados...\")\n",
    "\n",
    "# Carregar a tabela final da camada Gold\n",
    "df_features = spark.table(f\"{gold_schema}.feature_store\")\n",
    "\n",
    "# Divisão aleatória dos dados\n",
    "(df_treino, df_teste) = df_features.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "print(f\"Total de partidas: {df_features.count()}\")\n",
    "print(f\"Partidas para Treino (80%): {df_treino.count()}\")\n",
    "print(f\"Partidas para Teste (20%): {df_teste.count()}\")\n",
    "\n",
    "\n",
    "# --- AJUSTE DEFINITIVO: INDEXAÇÃO MANUAL VIA JOIN PARA EVITAR O BUG DO .fit() ---\n",
    "\n",
    "# 1. Obter os labels distintos e atribuir um ID (índice) a cada um.\n",
    "#    A função window row_number() cria os índices 0, 1, 2...\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "df_labels_map = df_features.select(\"resultado\").distinct() \\\n",
    "    .withColumn(\"label\", (F.row_number().over(Window.orderBy(\"resultado\")) - 1).cast(\"double\"))\n",
    "\n",
    "print(\"\\nDicionário de Mapeamento (Label -> Índice) criado:\")\n",
    "display(df_labels_map)\n",
    "\n",
    "# 2. Usar um JOIN para adicionar a coluna 'label' aos DataFrames de treino e teste.\n",
    "#    Esta operação é fundamental no Spark e não sofre do bug de tamanho.\n",
    "df_treino = df_treino.join(df_labels_map, on=\"resultado\", how=\"inner\")\n",
    "df_teste = df_teste.join(df_labels_map, on=\"resultado\", how=\"inner\")\n",
    "\n",
    "# --- FIM DO AJUSTE ---\n",
    "\n",
    "print(\"\\nAmostra do DataFrame de Treino (agora com a coluna 'label' adicionada via join):\")\n",
    "display(df_treino.limit(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc178f04-5b60-47e2-81a0-e1dd5b6c647a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# PASSO 2: TREINAR OS MODELOS ESPECIALISTAS (NÍVEL 1)\n",
    "# ==============================================================================\n",
    "print(\"Treinando os 3 modelos especialistas do Nível 1...\")\n",
    "\n",
    "# --- Modelo A: O Generalista (RandomForestClassifier) ---\n",
    "# Usa todas as features disponíveis\n",
    "features_gerais_nomes = [col for col in df_treino.columns if col not in [\"partida_id\", \"rodada\", \"mandante_id\", \"visitante_id\", \"resultado\", \"label\"]]\n",
    "\n",
    "# Converter todas as features para DoubleType para garantir consistência\n",
    "df_treino_geral = df_treino.select(\n",
    "    \"label\",\n",
    "    *[F.col(c).cast(\"double\").alias(c) for c in features_gerais_nomes]\n",
    ")\n",
    "\n",
    "va_geral = VectorAssembler(inputCols=features_gerais_nomes, outputCol=\"features\")\n",
    "\n",
    "# AJUSTE: Trocado GBTClassifier por RandomForestClassifier, que suporta multiclass\n",
    "rf_geral = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", numTrees=100, maxDepth=5)\n",
    "\n",
    "pipeline_geral = Pipeline(stages=[va_geral, rf_geral])\n",
    "modelo_geral = pipeline_geral.fit(df_treino_geral)\n",
    "print(\"  - ✅ Modelo A (Generalista - RandomForest) treinado.\")\n",
    "\n",
    "\n",
    "# --- Modelo B: O Estatístico (Regressão Logística) ---\n",
    "# Este modelo já suporta multiclass nativamente\n",
    "features_estatisticas_nomes = [\"elo_mandante_pre_jogo\", \"elo_visitante_pre_jogo\", \"elo_diff\", \"mm_gols_m\", \"mm_gols_v\", \"diff_mm_gols\"]\n",
    "\n",
    "df_treino_lr = df_treino.select(\n",
    "    \"label\",\n",
    "    *[F.col(c).cast(\"double\").alias(c) for c in features_estatisticas_nomes]\n",
    ")\n",
    "\n",
    "va_estatistico = VectorAssembler(inputCols=features_estatisticas_nomes, outputCol=\"features\")\n",
    "lr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\", maxIter=20)\n",
    "pipeline_lr = Pipeline(stages=[va_estatistico, lr])\n",
    "modelo_lr = pipeline_lr.fit(df_treino_lr)\n",
    "print(\"  - ✅ Modelo B (Estatístico - Regressão Logística) treinado.\")\n",
    "\n",
    "\n",
    "# --- Modelo C: O Tático (Random Forest) ---\n",
    "# Este modelo também já suporta multiclass nativamente\n",
    "features_taticas_nomes = [\"diff_mm_fin\", \"diff_mm_des\"]\n",
    "\n",
    "df_treino_rf = df_treino.select(\n",
    "    \"label\",\n",
    "    *[F.col(c).cast(\"double\").alias(c) for c in features_taticas_nomes]\n",
    ")\n",
    "\n",
    "va_tatico = VectorAssembler(inputCols=features_taticas_nomes, outputCol=\"features\")\n",
    "rf_tatico = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", numTrees=50, maxDepth=5)\n",
    "pipeline_rf = Pipeline(stages=[va_tatico, rf_tatico])\n",
    "modelo_rf = pipeline_rf.fit(df_treino_rf)\n",
    "print(\"  - ✅ Modelo C (Tático - RandomForest) treinado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f097dd6-66b8-4978-b419-13b1ad88393f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# PASSO 3: GERAR PREVISÕES E AVALIAR CADA ESPECIALISTA INDIVIDUALMENTE\n",
    "# ==============================================================================\n",
    "print(\"Gerando previsões dos especialistas e avaliando cada um...\")\n",
    "\n",
    "# Obter as previsões de cada modelo especialista\n",
    "pred_geral = modelo_geral.transform(df_teste) \n",
    "pred_lr = modelo_lr.transform(df_teste)\n",
    "pred_rf = modelo_rf.transform(df_teste)\n",
    "\n",
    "# --- AVALIAÇÃO INDIVIDUAL ---\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "acc_geral = evaluator.evaluate(pred_geral)\n",
    "acc_lr = evaluator.evaluate(pred_lr)\n",
    "acc_rf = evaluator.evaluate(pred_rf)\n",
    "\n",
    "print(\"\\n--- Acurácia dos Modelos Especialistas (Nível 1) ---\")\n",
    "print(f\"  - Modelo A (Generalista - RandomForest): {acc_geral:.2%}\")\n",
    "print(f\"  - Modelo B (Estatístico - Regressão Log.): {acc_lr:.2%}\")\n",
    "print(f\"  - Modelo C (Tático - RandomForest): {acc_rf:.2%}\")\n",
    "\n",
    "\n",
    "# --- PREPARAÇÃO PARA O META-MODELO ---\n",
    "# Renomear as colunas de probabilidade para evitar conflitos\n",
    "meta_features_geral = pred_geral.select(\"partida_id\", \"label\", F.col(\"probability\").alias(\"prob_geral\"))\n",
    "meta_features_lr = pred_lr.select(\"partida_id\", F.col(\"probability\").alias(\"prob_lr\"))\n",
    "meta_features_rf = pred_rf.select(\"partida_id\", F.col(\"probability\").alias(\"prob_rf\"))\n",
    "\n",
    "# Juntar as previsões para formar o DataFrame de treino do Nível 2\n",
    "df_treino_meta = meta_features_geral.join(meta_features_lr, \"partida_id\").join(meta_features_rf, \"partida_id\")\n",
    "\n",
    "# Criar um único vetor de features para o meta-modelo\n",
    "assembler_meta = VectorAssembler(inputCols=[\"prob_geral\", \"prob_lr\", \"prob_rf\"], outputCol=\"features\")\n",
    "df_treino_meta = assembler_meta.transform(df_treino_meta)\n",
    "\n",
    "print(\"\\n✅ Meta-features criadas com sucesso para o Nível 2.\")\n",
    "display(df_treino_meta.limit(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f97de204-6de7-456c-9e44-a4e0da1ee5e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# PASSO 4: TREINAR, AVALIAR E SALVAR OS RESULTADOS DO META-MODELO (NÍVEL 2)\n",
    "# ==============================================================================\n",
    "print(\"Treinando e avaliando o meta-modelo final...\")\n",
    "\n",
    "# Usaremos uma Regressão Logística como o \"blender\" final.\n",
    "meta_modelo = LogisticRegression(labelCol=\"label\", featuresCol=\"features\", maxIter=20)\n",
    "modelo_final = meta_modelo.fit(df_treino_meta)\n",
    "\n",
    "# Fazer as previsões finais no mesmo dataset de teste\n",
    "previsoes_finais = modelo_final.transform(df_treino_meta)\n",
    "\n",
    "# Avaliar a performance\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "acuracia = evaluator.evaluate(previsoes_finais)\n",
    "\n",
    "print(f\"\\n--- AVALIAÇÃO FINAL DO MODELO HÍBRIDO ---\")\n",
    "print(f\"🎯 Acurácia nas últimas 5 rodadas: {acuracia:.2%}\")\n",
    "\n",
    "# Exibir a Matriz de Confusão para uma análise mais detalhada\n",
    "print(\"\\nMatriz de Confusão:\")\n",
    "display(previsoes_finais.groupBy(\"label\", \"prediction\").count())\n",
    "\n",
    "\n",
    "# --- AJUSTE APLICADO AQUI: PERSISTINDO OS RESULTADOS NA CAMADA DIAMOND ---\n",
    "\n",
    "# Selecionar as colunas mais importantes para a análise de performance\n",
    "df_resultados_diamond = previsoes_finais.select(\n",
    "    \"partida_id\",\n",
    "    \"label\",         # O resultado real (0=V_MAND, 1=EMP, 2=V_VIS)\n",
    "    \"prediction\",    # A previsão do nosso modelo\n",
    "    \"probability\"    # A confiança do modelo em cada uma das 3 classes\n",
    ")\n",
    "\n",
    "# Salvar esta tabela de resultados na Camada Diamond\n",
    "df_resultados_diamond.write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .format(\"delta\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(f\"{diamond_schema}.previsoes_validadas\")\n",
    "\n",
    "print(f\"\\n✅ Tabela de previsões e resultados salva com sucesso em '{diamond_schema}.previsoes_validadas'\")\n",
    "\n",
    "# Em um cenário de produção, você também salvaria o objeto do modelo treinado,\n",
    "# geralmente usando MLflow, que se integra perfeitamente ao Databricks.\n",
    "# mlflow.spark.log_model(modelo_final, \"modelo_previsao_brasileirao\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6922909d-acca-4fcb-907c-f4937c24927e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# VERIFICAÇÃO PRÉ-EXECUÇÃO: Execute ANTES do Passo 5\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"VERIFICAÇÃO PRÉ-EXECUÇÃO DO PASSO 5\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Lista de variáveis que DEVEM existir\n",
    "variaveis_necessarias = {\n",
    "    'modelo_geral': 'Modelo Generalista (RandomForest)',\n",
    "    'modelo_lr': 'Modelo Estatístico (Logistic Regression)',\n",
    "    'modelo_rf': 'Modelo Tático (RandomForest)',\n",
    "    'modelo_final': 'Meta-Modelo (Logistic Regression)',\n",
    "    'df_labels_map': 'Mapeamento de Labels',\n",
    "    'acc_geral': 'Acurácia do Modelo Geral',\n",
    "    'acc_lr': 'Acurácia do Modelo LR',\n",
    "    'acc_rf': 'Acurácia do Modelo RF',\n",
    "    'acuracia': 'Acurácia do Meta-Modelo',\n",
    "    'df_treino': 'DataFrame de Treino',\n",
    "    'df_teste': 'DataFrame de Teste'\n",
    "}\n",
    "\n",
    "print(\"\\n🔍 Verificando variáveis necessárias...\\n\")\n",
    "\n",
    "todas_ok = True\n",
    "variaveis_faltando = []\n",
    "\n",
    "for var_nome, descricao in variaveis_necessarias.items():\n",
    "    if var_nome in dir():\n",
    "        # Verificar o tipo da variável\n",
    "        var_obj = eval(var_nome)\n",
    "        tipo = type(var_obj).__name__\n",
    "        \n",
    "        # Para DataFrames, mostrar a contagem\n",
    "        if 'df_' in var_nome:\n",
    "            try:\n",
    "                count = var_obj.count()\n",
    "                print(f\"✅ {var_nome:<20} ({descricao}) - {count:,} registros\")\n",
    "            except:\n",
    "                print(f\"✅ {var_nome:<20} ({descricao})\")\n",
    "        # Para métricas, mostrar o valor\n",
    "        elif 'acc' in var_nome or var_nome == 'acuracia':\n",
    "            print(f\"✅ {var_nome:<20} ({descricao}) - {var_obj:.2%}\")\n",
    "        else:\n",
    "            print(f\"✅ {var_nome:<20} ({descricao})\")\n",
    "    else:\n",
    "        print(f\"❌ {var_nome:<20} ({descricao}) - NÃO ENCONTRADA\")\n",
    "        todas_ok = False\n",
    "        variaveis_faltando.append(var_nome)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "if todas_ok:\n",
    "    print(\"✅ TUDO PRONTO! Você pode executar o Passo 5.\")\n",
    "    print(\"=\"*80)\n",
    "else:\n",
    "    print(\"❌ ATENÇÃO! Algumas variáveis estão faltando.\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\nVariáveis faltando: {', '.join(variaveis_faltando)}\")\n",
    "    print(\"\\n🔧 SOLUÇÃO:\")\n",
    "    print(\"1. NÃO execute o Passo 5 ainda\")\n",
    "    print(\"2. Volte e execute TODOS os passos anteriores:\")\n",
    "    print(\"   - PASSO 1: Configurações\")\n",
    "    print(\"   - PASSO 2: Carregar e dividir dados\")\n",
    "    print(\"   - PASSO 3: Treinar modelos especialistas\")\n",
    "    print(\"   - PASSO 4: Gerar previsões e avaliar\")\n",
    "    print(\"   - (PASSO 4 continuação): Treinar meta-modelo\")\n",
    "    print(\"3. Aguarde CADA passo terminar completamente\")\n",
    "    print(\"4. Execute esta verificação novamente\")\n",
    "    print(\"5. Só execute o Passo 5 quando tudo estiver ✅\")\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# Informações adicionais úteis\n",
    "print(\"\\nℹ️ INFORMAÇÕES DO AMBIENTE:\")\n",
    "print(f\"   Catálogo atual: {spark.catalog.currentCatalog()}\")\n",
    "print(f\"   Schema atual: {spark.catalog.currentDatabase()}\")\n",
    "\n",
    "# Verificar se o schema diamond existe\n",
    "try:\n",
    "    tabelas = spark.sql(\"SHOW TABLES IN previsao_brasileirao.diamond\").collect()\n",
    "    print(f\"   Tabelas em 'diamond': {len(tabelas)}\")\n",
    "except Exception as e:\n",
    "    print(f\"   ⚠️ Schema 'diamond' pode não existir: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32800536-399e-4ca4-90e0-0cb744dcf1fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# PASSO 5: SALVAR MODELOS (COM SUPORTE A VOLUMES)\n",
    "# ==============================================================================\n",
    "import mlflow\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"SALVANDO MODELOS - DATABRICKS SERVERLESS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "schema_destino = \"diamond\"\n",
    "\n",
    "# ==============================================================================\n",
    "# PASSO 1: CRIAR/VERIFICAR VOLUME PARA MODELOS\n",
    "# ==============================================================================\n",
    "print(\"\\n[Configuração] Criando estrutura de Volumes...\")\n",
    "\n",
    "# Criar o volume se não existir\n",
    "try:\n",
    "    spark.sql(f\"\"\"\n",
    "        CREATE VOLUME IF NOT EXISTS previsao_brasileirao.{schema_destino}.mlflow_models\n",
    "        COMMENT 'Volume para armazenamento temporário de modelos MLflow'\n",
    "    \"\"\")\n",
    "    print(\"  ✅ Volume 'mlflow_models' configurado\")\n",
    "except Exception as e:\n",
    "    print(f\"  ℹ️ Volume já existe ou erro: {e}\")\n",
    "\n",
    "# Definir o caminho do volume\n",
    "volume_path = f\"/Volumes/previsao_brasileirao/{schema_destino}/mlflow_models\"\n",
    "print(f\"  📁 Caminho do volume: {volume_path}\")\n",
    "\n",
    "# Configurar variável de ambiente (alternativa 1)\n",
    "os.environ['MLFLOW_DFS_TMP'] = volume_path\n",
    "\n",
    "# ==============================================================================\n",
    "# PASSO 2: CONFIGURAR MLFLOW\n",
    "# ==============================================================================\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "# Encerrar run anterior se existir\n",
    "try:\n",
    "    mlflow.end_run()\n",
    "    print(\"  ℹ️ Run anterior encerrada\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Configurar experimento\n",
    "experiment_name = \"/Shared/previsao_brasileirao\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "print(f\"  📝 Experimento: {experiment_name}\")\n",
    "\n",
    "# ==============================================================================\n",
    "# PASSO 3: SALVAR MODELOS\n",
    "# ==============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"INICIANDO SALVAMENTO DOS MODELOS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "with mlflow.start_run(run_name=f\"treinamento_{datetime.now().strftime('%Y%m%d_%H%M%S')}\") as run:\n",
    "    \n",
    "    run_id = run.info.run_id\n",
    "    print(f\"\\n🆔 Run ID: {run_id}\")\n",
    "    print(f\"📝 COPIE E GUARDE ESTE ID!\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # ========== SALVAR MODELO 1: GERAL ==========\n",
    "    print(\"\\n[1/4] Salvando Modelo Geral...\")\n",
    "    try:\n",
    "        mlflow.spark.log_model(\n",
    "            spark_model=modelo_geral,\n",
    "            artifact_path=\"modelo_geral\",\n",
    "            dfs_tmpdir=volume_path  # Especificar volume explicitamente\n",
    "        )\n",
    "        print(\"  ✅ Modelo Geral salvo!\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ❌ Erro: {e}\")\n",
    "        raise\n",
    "    \n",
    "    # ========== SALVAR MODELO 2: LR ==========\n",
    "    print(\"\\n[2/4] Salvando Modelo LR...\")\n",
    "    try:\n",
    "        mlflow.spark.log_model(\n",
    "            spark_model=modelo_lr,\n",
    "            artifact_path=\"modelo_lr\",\n",
    "            dfs_tmpdir=volume_path\n",
    "        )\n",
    "        print(\"  ✅ Modelo LR salvo!\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ❌ Erro: {e}\")\n",
    "        raise\n",
    "    \n",
    "    # ========== SALVAR MODELO 3: RF ==========\n",
    "    print(\"\\n[3/4] Salvando Modelo RF...\")\n",
    "    try:\n",
    "        mlflow.spark.log_model(\n",
    "            spark_model=modelo_rf,\n",
    "            artifact_path=\"modelo_rf\",\n",
    "            dfs_tmpdir=volume_path\n",
    "        )\n",
    "        print(\"  ✅ Modelo RF salvo!\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ❌ Erro: {e}\")\n",
    "        raise\n",
    "    \n",
    "    # ========== SALVAR MODELO 4: FINAL ==========\n",
    "    print(\"\\n[4/4] Salvando Meta-Modelo...\")\n",
    "    try:\n",
    "        mlflow.spark.log_model(\n",
    "            spark_model=modelo_final,\n",
    "            artifact_path=\"modelo_final\",\n",
    "            dfs_tmpdir=volume_path\n",
    "        )\n",
    "        print(\"  ✅ Meta-Modelo salvo!\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ❌ Erro: {e}\")\n",
    "        raise\n",
    "    \n",
    "    # ========== SALVAR MÉTRICAS ==========\n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"Salvando métricas...\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    mlflow.log_metric(\"acuracia_geral\", float(acc_geral))\n",
    "    mlflow.log_metric(\"acuracia_lr\", float(acc_lr))\n",
    "    mlflow.log_metric(\"acuracia_rf\", float(acc_rf))\n",
    "    mlflow.log_metric(\"acuracia_final\", float(acuracia))\n",
    "    \n",
    "    mlflow.log_param(\"num_treino\", df_treino.count())\n",
    "    mlflow.log_param(\"num_teste\", df_teste.count())\n",
    "    mlflow.log_param(\"data_treinamento\", datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    mlflow.log_param(\"volume_path\", volume_path)\n",
    "    \n",
    "    print(\"  ✅ Métricas e parâmetros salvos!\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"✅ TODOS OS MODELOS SALVOS COM SUCESSO!\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "# ==============================================================================\n",
    "# PASSO 4: CRIAR TABELA DE METADADOS\n",
    "# ==============================================================================\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"Criando tabela de metadados...\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "modelos_info = spark.createDataFrame([\n",
    "    {\n",
    "        \"nome_modelo\": \"modelo_geral\",\n",
    "        \"tipo\": \"RandomForestClassifier\",\n",
    "        \"features\": \"todas\",\n",
    "        \"acuracia\": float(acc_geral),\n",
    "        \"run_id\": run_id,\n",
    "        \"caminho_mlflow\": f\"runs:/{run_id}/modelo_geral\",\n",
    "        \"volume_path\": volume_path,\n",
    "        \"data_registro\": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        \"ativo\": True,\n",
    "        \"versao\": 1\n",
    "    },\n",
    "    {\n",
    "        \"nome_modelo\": \"modelo_lr\",\n",
    "        \"tipo\": \"LogisticRegression\",\n",
    "        \"features\": \"estatisticas\",\n",
    "        \"acuracia\": float(acc_lr),\n",
    "        \"run_id\": run_id,\n",
    "        \"caminho_mlflow\": f\"runs:/{run_id}/modelo_lr\",\n",
    "        \"volume_path\": volume_path,\n",
    "        \"data_registro\": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        \"ativo\": True,\n",
    "        \"versao\": 1\n",
    "    },\n",
    "    {\n",
    "        \"nome_modelo\": \"modelo_rf\",\n",
    "        \"tipo\": \"RandomForestClassifier\",\n",
    "        \"features\": \"taticas\",\n",
    "        \"acuracia\": float(acc_rf),\n",
    "        \"run_id\": run_id,\n",
    "        \"caminho_mlflow\": f\"runs:/{run_id}/modelo_rf\",\n",
    "        \"volume_path\": volume_path,\n",
    "        \"data_registro\": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        \"ativo\": True,\n",
    "        \"versao\": 1\n",
    "    },\n",
    "    {\n",
    "        \"nome_modelo\": \"modelo_final\",\n",
    "        \"tipo\": \"LogisticRegression (Meta)\",\n",
    "        \"features\": \"meta_features\",\n",
    "        \"acuracia\": float(acuracia),\n",
    "        \"run_id\": run_id,\n",
    "        \"caminho_mlflow\": f\"runs:/{run_id}/modelo_final\",\n",
    "        \"volume_path\": volume_path,\n",
    "        \"data_registro\": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        \"ativo\": True,\n",
    "        \"versao\": 1\n",
    "    }\n",
    "])\n",
    "\n",
    "# Salvar tabela\n",
    "modelos_info.write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .format(\"delta\") \\\n",
    "    .saveAsTable(f\"{schema_destino}.modelos_registry\")\n",
    "\n",
    "print(f\"  ✅ Tabela '{schema_destino}.modelos_registry' criada!\")\n",
    "\n",
    "# Atualizar label mapping\n",
    "df_labels_map.write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .format(\"delta\") \\\n",
    "    .saveAsTable(f\"{schema_destino}.label_mapping\")\n",
    "\n",
    "print(f\"  ✅ Tabela '{schema_destino}.label_mapping' atualizada!\")\n",
    "\n",
    "# ==============================================================================\n",
    "# PASSO 5: VERIFICAÇÃO FINAL\n",
    "# ==============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"VERIFICAÇÃO FINAL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n📊 Tabela de Metadados dos Modelos:\")\n",
    "display(spark.table(f\"{schema_destino}.modelos_registry\"))\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"INFORMAÇÕES IMPORTANTES\")\n",
    "print(\"-\"*80)\n",
    "print(f\"\\n🆔 RUN_ID: {run_id}\")\n",
    "print(f\"📁 Volume: {volume_path}\")\n",
    "print(f\"\\n✅ Para carregar os modelos no notebook de inferência:\")\n",
    "print(f\"   import mlflow\")\n",
    "print(f\"   import os\")\n",
    "print(f\"   os.environ['MLFLOW_DFS_TMP'] = '{volume_path}'\")\n",
    "print(f\"   modelo = mlflow.spark.load_model('runs:/{run_id}/modelo_geral', dfs_tmpdir='{volume_path}')\")\n",
    "\n",
    "# ==============================================================================\n",
    "# PASSO 6: TESTE DE CARREGAMENTO\n",
    "# ==============================================================================\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"TESTE: Validando carregamento dos modelos...\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "try:\n",
    "    teste = mlflow.spark.load_model(\n",
    "        f\"runs:/{run_id}/modelo_final\",\n",
    "        dfs_tmpdir=volume_path\n",
    "    )\n",
    "    print(\"✅ TESTE PASSOU! Os modelos podem ser carregados.\")\n",
    "    print(\"   Você pode prosseguir para o notebook de inferência.\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ TESTE FALHOU: {e}\")\n",
    "    print(\"   ⚠️ Pode haver problemas no notebook de inferência.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"✅✅✅ PROCESSO COMPLETO! ✅✅✅\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\n🎯 Próximo passo:\")\n",
    "print(\"   Execute o notebook '05_Diamond_Inference_Pipeline'\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "04_Diamond_Model_Training_and_Evaluation",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
