{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f44f0940-2047-4e73-abda-4a9e2dbb2d70",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CONFIGURA√á√ïES E IMPORTS\n",
    "# ==============================================================================\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier\n",
    "# Para o XGBoost, a instala√ß√£o e importa√ß√£o pode variar no Databricks\n",
    "# Vamos usar o GBTClassifier como um substituto poderoso e nativo do Spark\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.sql import functions as F\n",
    "import pandas as pd\n",
    "\n",
    "# Configurar o uso do nosso cat√°logo e dos schemas\n",
    "spark.sql(\"USE CATALOG previsao_brasileirao\")\n",
    "gold_schema = \"gold\"\n",
    "diamond_schema = \"diamond\"\n",
    "\n",
    "print(f\"Lendo dados de: {gold_schema}\")\n",
    "print(f\"Salvando modelos e m√©tricas em: {diamond_schema}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d557b8cf-500a-4708-b754-30451951897d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# PASSO 1: CARREGAR A FEATURE STORE E DIVIDIR EM TREINO/TESTE\n",
    "# ==============================================================================\n",
    "print(\"Carregando feature_store e dividindo os dados...\")\n",
    "\n",
    "# Carregar a tabela final da camada Gold\n",
    "df_features = spark.table(f\"{gold_schema}.feature_store\")\n",
    "\n",
    "# Divis√£o aleat√≥ria dos dados\n",
    "(df_treino, df_teste) = df_features.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "print(f\"Total de partidas: {df_features.count()}\")\n",
    "print(f\"Partidas para Treino (80%): {df_treino.count()}\")\n",
    "print(f\"Partidas para Teste (20%): {df_teste.count()}\")\n",
    "\n",
    "\n",
    "# --- AJUSTE DEFINITIVO: INDEXA√á√ÉO MANUAL VIA JOIN PARA EVITAR O BUG DO .fit() ---\n",
    "\n",
    "# 1. Obter os labels distintos e atribuir um ID (√≠ndice) a cada um.\n",
    "#    A fun√ß√£o window row_number() cria os √≠ndices 0, 1, 2...\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "df_labels_map = df_features.select(\"resultado\").distinct() \\\n",
    "    .withColumn(\"label\", (F.row_number().over(Window.orderBy(\"resultado\")) - 1).cast(\"double\"))\n",
    "\n",
    "print(\"\\nDicion√°rio de Mapeamento (Label -> √çndice) criado:\")\n",
    "display(df_labels_map)\n",
    "\n",
    "# 2. Usar um JOIN para adicionar a coluna 'label' aos DataFrames de treino e teste.\n",
    "#    Esta opera√ß√£o √© fundamental no Spark e n√£o sofre do bug de tamanho.\n",
    "df_treino = df_treino.join(df_labels_map, on=\"resultado\", how=\"inner\")\n",
    "df_teste = df_teste.join(df_labels_map, on=\"resultado\", how=\"inner\")\n",
    "\n",
    "# --- FIM DO AJUSTE ---\n",
    "\n",
    "print(\"\\nAmostra do DataFrame de Treino (agora com a coluna 'label' adicionada via join):\")\n",
    "display(df_treino.limit(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc178f04-5b60-47e2-81a0-e1dd5b6c647a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# PASSO 2: TREINAR OS MODELOS ESPECIALISTAS (N√çVEL 1)\n",
    "# ==============================================================================\n",
    "print(\"Treinando os 3 modelos especialistas do N√≠vel 1...\")\n",
    "\n",
    "# --- Modelo A: O Generalista (RandomForestClassifier) ---\n",
    "# Usa todas as features dispon√≠veis\n",
    "features_gerais_nomes = [col for col in df_treino.columns if col not in [\"partida_id\", \"rodada\", \"mandante_id\", \"visitante_id\", \"resultado\", \"label\"]]\n",
    "\n",
    "# Converter todas as features para DoubleType para garantir consist√™ncia\n",
    "df_treino_geral = df_treino.select(\n",
    "    \"label\",\n",
    "    *[F.col(c).cast(\"double\").alias(c) for c in features_gerais_nomes]\n",
    ")\n",
    "\n",
    "va_geral = VectorAssembler(inputCols=features_gerais_nomes, outputCol=\"features\")\n",
    "\n",
    "# AJUSTE: Trocado GBTClassifier por RandomForestClassifier, que suporta multiclass\n",
    "rf_geral = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", numTrees=100, maxDepth=5)\n",
    "\n",
    "pipeline_geral = Pipeline(stages=[va_geral, rf_geral])\n",
    "modelo_geral = pipeline_geral.fit(df_treino_geral)\n",
    "print(\"  - ‚úÖ Modelo A (Generalista - RandomForest) treinado.\")\n",
    "\n",
    "\n",
    "# --- Modelo B: O Estat√≠stico (Regress√£o Log√≠stica) ---\n",
    "# Este modelo j√° suporta multiclass nativamente\n",
    "features_estatisticas_nomes = [\"elo_mandante_pre_jogo\", \"elo_visitante_pre_jogo\", \"elo_diff\", \"mm_gols_m\", \"mm_gols_v\", \"diff_mm_gols\"]\n",
    "\n",
    "df_treino_lr = df_treino.select(\n",
    "    \"label\",\n",
    "    *[F.col(c).cast(\"double\").alias(c) for c in features_estatisticas_nomes]\n",
    ")\n",
    "\n",
    "va_estatistico = VectorAssembler(inputCols=features_estatisticas_nomes, outputCol=\"features\")\n",
    "lr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\", maxIter=20)\n",
    "pipeline_lr = Pipeline(stages=[va_estatistico, lr])\n",
    "modelo_lr = pipeline_lr.fit(df_treino_lr)\n",
    "print(\"  - ‚úÖ Modelo B (Estat√≠stico - Regress√£o Log√≠stica) treinado.\")\n",
    "\n",
    "\n",
    "# --- Modelo C: O T√°tico (Random Forest) ---\n",
    "# Este modelo tamb√©m j√° suporta multiclass nativamente\n",
    "features_taticas_nomes = [\"diff_mm_fin\", \"diff_mm_des\"]\n",
    "\n",
    "df_treino_rf = df_treino.select(\n",
    "    \"label\",\n",
    "    *[F.col(c).cast(\"double\").alias(c) for c in features_taticas_nomes]\n",
    ")\n",
    "\n",
    "va_tatico = VectorAssembler(inputCols=features_taticas_nomes, outputCol=\"features\")\n",
    "rf_tatico = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", numTrees=50, maxDepth=5)\n",
    "pipeline_rf = Pipeline(stages=[va_tatico, rf_tatico])\n",
    "modelo_rf = pipeline_rf.fit(df_treino_rf)\n",
    "print(\"  - ‚úÖ Modelo C (T√°tico - RandomForest) treinado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f097dd6-66b8-4978-b419-13b1ad88393f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# PASSO 3: GERAR PREVIS√ïES E AVALIAR CADA ESPECIALISTA INDIVIDUALMENTE\n",
    "# ==============================================================================\n",
    "print(\"Gerando previs√µes dos especialistas e avaliando cada um...\")\n",
    "\n",
    "# Obter as previs√µes de cada modelo especialista\n",
    "pred_geral = modelo_geral.transform(df_teste) \n",
    "pred_lr = modelo_lr.transform(df_teste)\n",
    "pred_rf = modelo_rf.transform(df_teste)\n",
    "\n",
    "# --- AVALIA√á√ÉO INDIVIDUAL ---\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "acc_geral = evaluator.evaluate(pred_geral)\n",
    "acc_lr = evaluator.evaluate(pred_lr)\n",
    "acc_rf = evaluator.evaluate(pred_rf)\n",
    "\n",
    "print(\"\\n--- Acur√°cia dos Modelos Especialistas (N√≠vel 1) ---\")\n",
    "print(f\"  - Modelo A (Generalista - RandomForest): {acc_geral:.2%}\")\n",
    "print(f\"  - Modelo B (Estat√≠stico - Regress√£o Log.): {acc_lr:.2%}\")\n",
    "print(f\"  - Modelo C (T√°tico - RandomForest): {acc_rf:.2%}\")\n",
    "\n",
    "\n",
    "# --- PREPARA√á√ÉO PARA O META-MODELO ---\n",
    "# Renomear as colunas de probabilidade para evitar conflitos\n",
    "meta_features_geral = pred_geral.select(\"partida_id\", \"label\", F.col(\"probability\").alias(\"prob_geral\"))\n",
    "meta_features_lr = pred_lr.select(\"partida_id\", F.col(\"probability\").alias(\"prob_lr\"))\n",
    "meta_features_rf = pred_rf.select(\"partida_id\", F.col(\"probability\").alias(\"prob_rf\"))\n",
    "\n",
    "# Juntar as previs√µes para formar o DataFrame de treino do N√≠vel 2\n",
    "df_treino_meta = meta_features_geral.join(meta_features_lr, \"partida_id\").join(meta_features_rf, \"partida_id\")\n",
    "\n",
    "# Criar um √∫nico vetor de features para o meta-modelo\n",
    "assembler_meta = VectorAssembler(inputCols=[\"prob_geral\", \"prob_lr\", \"prob_rf\"], outputCol=\"features\")\n",
    "df_treino_meta = assembler_meta.transform(df_treino_meta)\n",
    "\n",
    "print(\"\\n‚úÖ Meta-features criadas com sucesso para o N√≠vel 2.\")\n",
    "display(df_treino_meta.limit(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f97de204-6de7-456c-9e44-a4e0da1ee5e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# PASSO 4: TREINAR, AVALIAR E SALVAR OS RESULTADOS DO META-MODELO (N√çVEL 2)\n",
    "# ==============================================================================\n",
    "print(\"Treinando e avaliando o meta-modelo final...\")\n",
    "\n",
    "# Usaremos uma Regress√£o Log√≠stica como o \"blender\" final.\n",
    "meta_modelo = LogisticRegression(labelCol=\"label\", featuresCol=\"features\", maxIter=20)\n",
    "modelo_final = meta_modelo.fit(df_treino_meta)\n",
    "\n",
    "# Fazer as previs√µes finais no mesmo dataset de teste\n",
    "previsoes_finais = modelo_final.transform(df_treino_meta)\n",
    "\n",
    "# Avaliar a performance\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "acuracia = evaluator.evaluate(previsoes_finais)\n",
    "\n",
    "print(f\"\\n--- AVALIA√á√ÉO FINAL DO MODELO H√çBRIDO ---\")\n",
    "print(f\"üéØ Acur√°cia nas √∫ltimas 5 rodadas: {acuracia:.2%}\")\n",
    "\n",
    "# Exibir a Matriz de Confus√£o para uma an√°lise mais detalhada\n",
    "print(\"\\nMatriz de Confus√£o:\")\n",
    "display(previsoes_finais.groupBy(\"label\", \"prediction\").count())\n",
    "\n",
    "\n",
    "# --- AJUSTE APLICADO AQUI: PERSISTINDO OS RESULTADOS NA CAMADA DIAMOND ---\n",
    "\n",
    "# Selecionar as colunas mais importantes para a an√°lise de performance\n",
    "df_resultados_diamond = previsoes_finais.select(\n",
    "    \"partida_id\",\n",
    "    \"label\",         # O resultado real (0=V_MAND, 1=EMP, 2=V_VIS)\n",
    "    \"prediction\",    # A previs√£o do nosso modelo\n",
    "    \"probability\"    # A confian√ßa do modelo em cada uma das 3 classes\n",
    ")\n",
    "\n",
    "# Salvar esta tabela de resultados na Camada Diamond\n",
    "df_resultados_diamond.write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .format(\"delta\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(f\"{diamond_schema}.previsoes_validadas\")\n",
    "\n",
    "print(f\"\\n‚úÖ Tabela de previs√µes e resultados salva com sucesso em '{diamond_schema}.previsoes_validadas'\")\n",
    "\n",
    "# Em um cen√°rio de produ√ß√£o, voc√™ tamb√©m salvaria o objeto do modelo treinado,\n",
    "# geralmente usando MLflow, que se integra perfeitamente ao Databricks.\n",
    "# mlflow.spark.log_model(modelo_final, \"modelo_previsao_brasileirao\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4abd0a05-88ca-4a70-ad56-998f8a3fb9df",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# PASSO 5 (FINAL E CORRIGIDO): SALVAR OS MODELOS E O MAPA DE LABELS\n",
    "# ==============================================================================\n",
    "import mlflow\n",
    "\n",
    "schema_destino = \"diamond\"\n",
    "dfs_tmpdir = f\"/Volumes/previsao_brasileirao/silver/mlflow_staging\"\n",
    "\n",
    "print(f\"Salvando modelos no schema '{schema_destino}' do Unity Catalog...\")\n",
    "\n",
    "# --- Esta parte j√° funcionou e est√° correta ---\n",
    "nome_completo_geral = f\"previsao_brasileirao.{schema_destino}.modelo_geral\"\n",
    "mlflow.spark.log_model(modelo_geral, nome_completo_geral, dfs_tmpdir=dfs_tmpdir)\n",
    "print(f\"  - ‚úÖ Modelo A (Generalista) salvo em '{nome_completo_geral}'.\")\n",
    "\n",
    "nome_completo_lr = f\"previsao_brasileirao.{schema_destino}.modelo_lr\"\n",
    "mlflow.spark.log_model(modelo_lr, nome_completo_lr, dfs_tmpdir=dfs_tmpdir)\n",
    "print(f\"  - ‚úÖ Modelo B (Estat√≠stico) salvo em '{nome_completo_lr}'.\")\n",
    "\n",
    "nome_completo_rf = f\"previsao_brasileirao.{schema_destino}.modelo_rf\"\n",
    "mlflow.spark.log_model(modelo_rf, nome_completo_rf, dfs_tmpdir=dfs_tmpdir)\n",
    "print(f\"  - ‚úÖ Modelo C (T√°tico) salvo em '{nome_completo_rf}'.\")\n",
    "\n",
    "nome_completo_final = f\"previsao_brasileirao.{schema_destino}.modelo_final\"\n",
    "mlflow.spark.log_model(modelo_final, nome_completo_final, dfs_tmpdir=dfs_tmpdir)\n",
    "print(f\"  - ‚úÖ Meta-Modelo salvo em '{nome_completo_final}'.\")\n",
    "# --- Fim da parte que j√° funcionou ---\n",
    "\n",
    "\n",
    "# --- AJUSTE APLICADO AQUI ---\n",
    "# REMOVIDO: A linha que tentava salvar 'label_indexer_model', que n√£o existe mais.\n",
    "# mlflow.spark.log_model(label_indexer_model, nome_completo_indexer, dfs_tmpdir=dfs_tmpdir)\n",
    "\n",
    "# ADICIONADO: Salvar nosso 'dicion√°rio' de mapeamento manual (o df_labels_map)\n",
    "# como uma tabela na camada Diamond. Esta √© a maneira correta de persistir o mapeamento.\n",
    "print(\"\\nSalvando o mapa de tradu√ß√£o de labels...\")\n",
    "df_labels_map.write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .format(\"delta\") \\\n",
    "    .saveAsTable(f\"{diamond_schema}.label_mapping\")\n",
    "print(f\"  - ‚úÖ Mapa de labels salvo com sucesso em '{diamond_schema}.label_mapping'.\")\n",
    "# --- FIM DO AJUSTE ---\n",
    "\n",
    "print(\"\\nTodos os artefatos foram salvos com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a2b975c-6211-4be7-91b7-b8ca2460c041",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# PASSO 6 (NOVO): DEFINIR ALIASES PARA OS MODELOS NO UNITY CATALOG\n",
    "# ==============================================================================\n",
    "import mlflow\n",
    "\n",
    "# Garantir que estamos apontando para o registro do Unity Catalog\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "\n",
    "# Lista dos modelos que salvamos\n",
    "nomes_dos_modelos = [\n",
    "    \"modelo_geral\",\n",
    "    \"modelo_lr\",\n",
    "    \"modelo_rf\",\n",
    "    \"modelo_final\",\n",
    "    \"label_indexer_model\"\n",
    "]\n",
    "\n",
    "# O nome completo de um modelo no UC √© <catalogo>.<schema>.<nome>\n",
    "# Vamos assumir que eles est√£o no schema 'diamond' para organiza√ß√£o\n",
    "schema_destino = \"diamond\" \n",
    "\n",
    "print(\"\\nDefinindo o alias '@Champion' para a vers√£o 1 de cada modelo...\")\n",
    "\n",
    "for nome in nomes_dos_modelos:\n",
    "    nome_completo_uc = f\"previsao_brasileirao.{schema_destino}.{nome}\"\n",
    "    try:\n",
    "        client.set_registered_model_alias(name=nome_completo_uc, alias=\"Champion\", version=1)\n",
    "        print(f\"  - ‚úÖ Alias '@Champion' definido para {nome_completo_uc}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  - ‚ö†Ô∏è  Aviso ao definir alias para {nome_completo_uc}: {e}\")\n",
    "\n",
    "print(\"\\nProcesso de defini√ß√£o de aliases conclu√≠do.\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "04_Diamond_Model_Training_and_Evaluation",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
