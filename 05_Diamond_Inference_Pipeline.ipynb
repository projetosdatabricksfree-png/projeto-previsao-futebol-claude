{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "79686acd-71bc-4cb8-ae4e-edaae7221cac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# NOTEBOOK DE INFER√äNCIA - PREVIS√ÉO DE PARTIDAS FUTURAS\n",
    "# ==============================================================================\n",
    "from pyspark.ml import PipelineModel\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.feature import IndexToString, VectorAssembler\n",
    "import mlflow\n",
    "import os\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"PIPELINE DE INFER√äNCIA - PREVIS√ÉO BRASILEIR√ÉO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "spark.sql(\"USE CATALOG previsao_brasileirao\")\n",
    "\n",
    "# ==============================================================================\n",
    "# PASSO 1: CONFIGURAR E CARREGAR MODELOS\n",
    "# ==============================================================================\n",
    "print(\"\\n[PASSO 1] Configurando ambiente e carregando modelos...\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "schema_modelos = \"diamond\"\n",
    "\n",
    "# CONFIGURA√á√ÉO CR√çTICA: Volume path para Databricks Serverless\n",
    "volume_path = \"/Volumes/previsao_brasileirao/diamond/mlflow_models\"\n",
    "os.environ['MLFLOW_DFS_TMP'] = volume_path\n",
    "\n",
    "print(f\"üìÅ Volume configurado: {volume_path}\")\n",
    "\n",
    "# Configurar MLflow\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "# Carregar metadados dos modelos\n",
    "df_modelos_info = spark.table(f\"{schema_modelos}.modelos_registry\") \\\n",
    "    .filter(\"ativo = true\") \\\n",
    "    .orderBy(F.desc(\"versao\"))\n",
    "\n",
    "print(\"\\nüìä Modelos dispon√≠veis:\")\n",
    "display(df_modelos_info.select(\"nome_modelo\", \"tipo\", \"acuracia\", \"run_id\"))\n",
    "\n",
    "# Pegar o run_id mais recente\n",
    "run_id = df_modelos_info.select(\"run_id\").first()[\"run_id\"]\n",
    "print(f\"\\n‚úÖ Usando Run ID: {run_id}\")\n",
    "\n",
    "# Carregar os modelos\n",
    "print(\"\\nCarregando modelos treinados...\")\n",
    "\n",
    "try:\n",
    "    modelo_geral = mlflow.spark.load_model(\n",
    "        f\"runs:/{run_id}/modelo_geral\",\n",
    "        dfs_tmpdir=volume_path\n",
    "    )\n",
    "    print(\"  ‚úÖ Modelo Geral carregado\")\n",
    "    \n",
    "    modelo_lr = mlflow.spark.load_model(\n",
    "        f\"runs:/{run_id}/modelo_lr\",\n",
    "        dfs_tmpdir=volume_path\n",
    "    )\n",
    "    print(\"  ‚úÖ Modelo LR carregado\")\n",
    "    \n",
    "    modelo_rf = mlflow.spark.load_model(\n",
    "        f\"runs:/{run_id}/modelo_rf\",\n",
    "        dfs_tmpdir=volume_path\n",
    "    )\n",
    "    print(\"  ‚úÖ Modelo RF carregado\")\n",
    "    \n",
    "    modelo_final = mlflow.spark.load_model(\n",
    "        f\"runs:/{run_id}/modelo_final\",\n",
    "        dfs_tmpdir=volume_path\n",
    "    )\n",
    "    print(\"  ‚úÖ Meta-Modelo carregado\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå ERRO ao carregar modelos: {e}\")\n",
    "    print(\"\\nüîß Poss√≠veis solu√ß√µes:\")\n",
    "    print(\"1. Verifique se o notebook '04_Diamond_Model_Training' foi executado\")\n",
    "    print(\"2. Execute novamente o PASSO 5 do notebook de treinamento\")\n",
    "    raise\n",
    "\n",
    "# Carregar mapa de labels\n",
    "df_labels_map = spark.table(f\"{schema_modelos}.label_mapping\")\n",
    "label_mapping_dict = {row['resultado']: row['label'] for row in df_labels_map.collect()}\n",
    "labels_array = [k for k, v in sorted(label_mapping_dict.items(), key=lambda x: x[1])]\n",
    "\n",
    "print(f\"\\n‚úÖ Labels mapeados: {labels_array}\")\n",
    "\n",
    "# Recriar transformadores\n",
    "assembler_meta = VectorAssembler(\n",
    "    inputCols=[\"prob_geral\", \"prob_lr\", \"prob_rf\"],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "converter = IndexToString(\n",
    "    inputCol=\"prediction\",\n",
    "    outputCol=\"previsao_texto\",\n",
    "    labels=labels_array\n",
    ")\n",
    "\n",
    "print(\"  ‚úÖ Transformadores criados\")\n",
    "\n",
    "# Carregar dados auxiliares\n",
    "df_partidas_historico = spark.table(\"gold.feature_store\")\n",
    "df_clubes = spark.table(\"silver.clubes\")\n",
    "\n",
    "print(f\"\\n‚úÖ Dados hist√≥ricos: {df_partidas_historico.count()} partidas\")\n",
    "print(f\"‚úÖ Clubes cadastrados: {df_clubes.count()}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ PASSO 1 CONCLU√çDO - Modelos carregados com sucesso!\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ==============================================================================\n",
    "# PASSO 2: CARREGAR E PREPARAR PARTIDAS FUTURAS\n",
    "# ==============================================================================\n",
    "print(\"\\n[PASSO 2] Carregando partidas futuras...\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "df_futuro_raw = spark.table(\"bronze.partidas_raw\") \\\n",
    "    .filter(\"placar_oficial_mandante IS NULL AND valida = true\") \\\n",
    "    .orderBy(\"partida_data\")\n",
    "\n",
    "num_partidas_futuras = df_futuro_raw.count()\n",
    "print(f\"\\nüìã Partidas futuras encontradas: {num_partidas_futuras}\")\n",
    "\n",
    "if num_partidas_futuras == 0:\n",
    "    print(\"\\n‚ö†Ô∏è ATEN√á√ÉO: Nenhuma partida futura encontrada!\")\n",
    "    print(\"\\nüí° Poss√≠veis motivos:\")\n",
    "    print(\"  - A rodada atual j√° foi conclu√≠da\")\n",
    "    print(\"  - A pr√≥xima rodada ainda n√£o foi disponibilizada pela API\")\n",
    "    print(\"\\nüîß Solu√ß√£o:\")\n",
    "    print(\"  Execute o notebook '01_Bronze_Ingestao' para atualizar os dados\")\n",
    "    \n",
    "    # Ainda assim, continuar para mostrar o processo\n",
    "    print(\"\\n  (Continuando com o processo para demonstra√ß√£o...)\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ Preview das partidas futuras:\")\n",
    "    display(df_futuro_raw.select(\n",
    "        \"partida_id\", \"rodada\", \"partida_data\",\n",
    "        \"clube_casa_id\", \"clube_visitante_id\"\n",
    "    ).limit(5))\n",
    "\n",
    "# ==============================================================================\n",
    "# PASSO 3: ENGENHARIA DE FEATURES PARA PARTIDAS FUTURAS\n",
    "# ==============================================================================\n",
    "print(\"\\n[PASSO 3] Aplicando engenharia de features...\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Pegar Elo mais recente de cada time\n",
    "latest_elos = df_partidas_historico \\\n",
    "    .groupBy(\"mandante_id\") \\\n",
    "    .agg(F.max(\"rodada\").alias(\"rodada\")) \\\n",
    "    .join(df_partidas_historico, [\"mandante_id\", \"rodada\"]) \\\n",
    "    .select(\"mandante_id\", F.col(\"elo_mandante_pre_jogo\").alias(\"elo_atual\"))\n",
    "\n",
    "# Pegar m√©dias m√≥veis mais recentes\n",
    "latest_mms_m = df_partidas_historico \\\n",
    "    .groupBy(\"mandante_id\") \\\n",
    "    .agg(F.max(\"rodada\").alias(\"rodada\")) \\\n",
    "    .join(df_partidas_historico, [\"mandante_id\", \"rodada\"]) \\\n",
    "    .select(\"mandante_id\", \"mm_gols_m\", \"mm_fin_m\", \"mm_des_m\")\n",
    "\n",
    "latest_mms_v = df_partidas_historico \\\n",
    "    .groupBy(\"visitante_id\") \\\n",
    "    .agg(F.max(\"rodada\").alias(\"rodada\")) \\\n",
    "    .join(df_partidas_historico, [\"visitante_id\", \"rodada\"]) \\\n",
    "    .select(\"visitante_id\", \"mm_gols_v\", \"mm_fin_v\", \"mm_des_v\")\n",
    "\n",
    "# Preparar partidas futuras\n",
    "df_futuro_features = df_futuro_raw.select(\n",
    "    F.col(\"partida_id\"),\n",
    "    F.col(\"rodada\"),\n",
    "    F.col(\"clube_casa_id\").alias(\"mandante_id\"),\n",
    "    F.col(\"clube_visitante_id\").alias(\"visitante_id\"),\n",
    "    F.to_timestamp(\"partida_data\").alias(\"data_partida\")\n",
    ")\n",
    "\n",
    "# Juntar Elo do mandante\n",
    "df_com_elo_m = df_futuro_features.join(\n",
    "    latest_elos,\n",
    "    df_futuro_features[\"mandante_id\"] == latest_elos[\"mandante_id\"],\n",
    "    \"left\"\n",
    ").withColumnRenamed(\"elo_atual\", \"elo_mandante_pre_jogo\") \\\n",
    " .drop(latest_elos[\"mandante_id\"])\n",
    "\n",
    "# Juntar Elo do visitante\n",
    "df_com_elo_mv = df_com_elo_m.join(\n",
    "    latest_elos,\n",
    "    df_com_elo_m[\"visitante_id\"] == latest_elos[\"mandante_id\"],\n",
    "    \"left\"\n",
    ").withColumnRenamed(\"elo_atual\", \"elo_visitante_pre_jogo\") \\\n",
    " .drop(latest_elos[\"mandante_id\"])\n",
    "\n",
    "# Juntar m√©dias m√≥veis do mandante\n",
    "df_com_mm_m = df_com_elo_mv.join(\n",
    "    latest_mms_m,\n",
    "    df_com_elo_mv[\"mandante_id\"] == latest_mms_m[\"mandante_id\"],\n",
    "    \"left\"\n",
    ").drop(latest_mms_m[\"mandante_id\"])\n",
    "\n",
    "# Juntar m√©dias m√≥veis do visitante\n",
    "df_com_tudo = df_com_mm_m.join(\n",
    "    latest_mms_v,\n",
    "    df_com_mm_m[\"visitante_id\"] == latest_mms_v[\"visitante_id\"],\n",
    "    \"left\"\n",
    ").drop(latest_mms_v[\"visitante_id\"])\n",
    "\n",
    "# Calcular diferenciais\n",
    "df_futuro_features_final = df_com_tudo \\\n",
    "    .withColumn(\"elo_diff\", F.col(\"elo_mandante_pre_jogo\") - F.col(\"elo_visitante_pre_jogo\")) \\\n",
    "    .withColumn(\"diff_mm_gols\", F.col(\"mm_gols_m\") - F.col(\"mm_gols_v\")) \\\n",
    "    .withColumn(\"diff_mm_fin\", F.col(\"mm_fin_m\") - F.col(\"mm_fin_v\")) \\\n",
    "    .withColumn(\"diff_mm_des\", F.col(\"mm_des_m\") - F.col(\"mm_des_v\")) \\\n",
    "    .na.fill(0)\n",
    "\n",
    "print(\"  ‚úÖ Features calculadas\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ PASSO 3 CONCLU√çDO - Features prontas!\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ==============================================================================\n",
    "# PASSO 4: FAZER PREVIS√ïES\n",
    "# ==============================================================================\n",
    "print(\"\\n[PASSO 4] Gerando previs√µes...\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "if num_partidas_futuras > 0:\n",
    "    # N√≠vel 1: Previs√µes dos especialistas\n",
    "    print(\"\\n  N√≠vel 1: Modelos Especialistas...\")\n",
    "    pred_geral_futuro = modelo_geral.transform(df_futuro_features_final)\n",
    "    pred_lr_futuro = modelo_lr.transform(df_futuro_features_final)\n",
    "    pred_rf_futuro = modelo_rf.transform(df_futuro_features_final)\n",
    "    print(\"    ‚úÖ Previs√µes dos especialistas geradas\")\n",
    "    \n",
    "    # Preparar meta-features\n",
    "    meta_features_geral = pred_geral_futuro.select(\"partida_id\", F.col(\"probability\").alias(\"prob_geral\"))\n",
    "    meta_features_lr = pred_lr_futuro.select(\"partida_id\", F.col(\"probability\").alias(\"prob_lr\"))\n",
    "    meta_features_rf = pred_rf_futuro.select(\"partida_id\", F.col(\"probability\").alias(\"prob_rf\"))\n",
    "    \n",
    "    df_inferencia_meta = df_futuro_features_final.select(\"partida_id\") \\\n",
    "        .join(meta_features_geral, \"partida_id\") \\\n",
    "        .join(meta_features_lr, \"partida_id\") \\\n",
    "        .join(meta_features_rf, \"partida_id\")\n",
    "    \n",
    "    df_inferencia_meta = assembler_meta.transform(df_inferencia_meta)\n",
    "    \n",
    "    # N√≠vel 2: Meta-modelo\n",
    "    print(\"  N√≠vel 2: Meta-Modelo...\")\n",
    "    previsoes_finais = modelo_final.transform(df_inferencia_meta)\n",
    "    print(\"    ‚úÖ Previs√µes finais geradas\")\n",
    "    \n",
    "    # Converter √≠ndices para texto\n",
    "    previsoes_texto = converter.transform(previsoes_finais)\n",
    "    \n",
    "    # Juntar com nomes dos clubes\n",
    "    df_resultado_final = df_futuro_features_final \\\n",
    "        .join(previsoes_texto.select(\"partida_id\", \"previsao_texto\", \"probability\"), \"partida_id\") \\\n",
    "        .join(df_clubes.alias(\"mandante\"), F.col(\"mandante_id\") == F.col(\"mandante.clube_id\")) \\\n",
    "        .join(df_clubes.alias(\"visitante\"), F.col(\"visitante_id\") == F.col(\"visitante.clube_id\")) \\\n",
    "        .withColumn(\"competicao\", F.lit(\"Brasileir√£o S√©rie A\")) \\\n",
    "        .select(\n",
    "            \"competicao\",\n",
    "            F.date_format(\"data_partida\", \"dd/MM/yyyy HH:mm\").alias(\"data_hora_partida\"),\n",
    "            F.col(\"mandante.nome\").alias(\"time_mandante\"),\n",
    "            F.col(\"visitante.nome\").alias(\"time_visitante\"),\n",
    "            F.col(\"previsao_texto\").alias(\"previsao\"),\n",
    "            F.col(\"probability\").alias(\"confianca_probabilidades\")\n",
    "        ).orderBy(\"data_hora_partida\")\n",
    "    \n",
    "    # Salvar na camada Diamond\n",
    "    df_resultado_final.write \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .format(\"delta\") \\\n",
    "        .saveAsTable(\"diamond.previsoes_proximas_partidas\")\n",
    "    \n",
    "    print(\"\\n  ‚úÖ Previs√µes salvas em 'diamond.previsoes_proximas_partidas'\")\n",
    "    \n",
    "    # Criar view tempor√°ria\n",
    "    df_resultado_final.createOrReplaceTempView(\"visualizacao_previsoes\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"‚úÖ PASSO 4 CONCLU√çDO - Previs√µes geradas!\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # ==============================================================================\n",
    "    # VISUALIZA√á√ÉO FINAL\n",
    "    # ==============================================================================\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìä PREVIS√ïES DAS PR√ìXIMAS PARTIDAS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    display(df_resultado_final)\n",
    "    \n",
    "    print(\"\\n‚úÖ Voc√™ pode consultar as previs√µes usando:\")\n",
    "    print(\"   SELECT * FROM diamond.previsoes_proximas_partidas\")\n",
    "    print(\"   ou\")\n",
    "    print(\"   SELECT * FROM visualizacao_previsoes\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Nenhuma previs√£o gerada pois n√£o h√° partidas futuras\")\n",
    "    print(\"   Execute o notebook '01_Bronze_Ingestao' e tente novamente\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ‚úÖ‚úÖ PIPELINE DE INFER√äNCIA CONCLU√çDO! ‚úÖ‚úÖ‚úÖ\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a35e43d-6e60-4230-9ae3-052673ad7c7a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# NOTEBOOK DE INFER√äNCIA - PREVIS√ÉO DE REBAIXAMENTO\n",
    "# ==============================================================================\n",
    "from pyspark.ml import PipelineModel\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.ml.feature import IndexToString, VectorAssembler\n",
    "import mlflow\n",
    "import os\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"PIPELINE DE INFER√äNCIA - PREVIS√ÉO DE REBAIXAMENTO BRASILEIR√ÉO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "spark.sql(\"USE CATALOG previsao_brasileirao\")\n",
    "\n",
    "# ==============================================================================\n",
    "# PASSO 1: CONFIGURAR E CARREGAR MODELOS\n",
    "# ==============================================================================\n",
    "print(\"\\n[PASSO 1] Configurando ambiente e carregando modelos...\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "schema_modelos = \"diamond\"\n",
    "\n",
    "# CONFIGURA√á√ÉO CR√çTICA: Volume path para Databricks Serverless\n",
    "volume_path = \"/Volumes/previsao_brasileirao/diamond/mlflow_models\"\n",
    "os.environ['MLFLOW_DFS_TMP'] = volume_path\n",
    "\n",
    "print(f\"üìÅ Volume configurado: {volume_path}\")\n",
    "\n",
    "# Configurar MLflow\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "# Carregar metadados dos modelos\n",
    "df_modelos_info = spark.table(f\"{schema_modelos}.modelos_registry\") \\\n",
    "    .filter(\"ativo = true\") \\\n",
    "    .orderBy(F.desc(\"versao\"))\n",
    "\n",
    "print(\"\\nüìä Modelos dispon√≠veis:\")\n",
    "display(df_modelos_info.select(\"nome_modelo\", \"tipo\", \"acuracia\", \"run_id\"))\n",
    "\n",
    "# Pegar o run_id mais recente\n",
    "run_id = df_modelos_info.select(\"run_id\").first()[\"run_id\"]\n",
    "print(f\"\\n‚úÖ Usando Run ID: {run_id}\")\n",
    "\n",
    "# Carregar os modelos\n",
    "print(\"\\nCarregando modelos treinados...\")\n",
    "\n",
    "try:\n",
    "    modelo_geral = mlflow.spark.load_model(\n",
    "        f\"runs:/{run_id}/modelo_geral\",\n",
    "        dfs_tmpdir=volume_path\n",
    "    )\n",
    "    print(\"  ‚úÖ Modelo Geral carregado\")\n",
    "    \n",
    "    modelo_lr = mlflow.spark.load_model(\n",
    "        f\"runs:/{run_id}/modelo_lr\",\n",
    "        dfs_tmpdir=volume_path\n",
    "    )\n",
    "    print(\"  ‚úÖ Modelo LR carregado\")\n",
    "    \n",
    "    modelo_rf = mlflow.spark.load_model(\n",
    "        f\"runs:/{run_id}/modelo_rf\",\n",
    "        dfs_tmpdir=volume_path\n",
    "    )\n",
    "    print(\"  ‚úÖ Modelo RF carregado\")\n",
    "    \n",
    "    modelo_final = mlflow.spark.load_model(\n",
    "        f\"runs:/{run_id}/modelo_final\",\n",
    "        dfs_tmpdir=volume_path\n",
    "    )\n",
    "    print(\"  ‚úÖ Meta-Modelo carregado\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå ERRO ao carregar modelos: {e}\")\n",
    "    print(\"\\nüîß Poss√≠veis solu√ß√µes:\")\n",
    "    print(\"1. Verifique se o notebook '04_Diamond_Model_Training' foi executado\")\n",
    "    print(\"2. Execute novamente o PASSO 5 do notebook de treinamento\")\n",
    "    raise\n",
    "\n",
    "# Carregar mapa de labels\n",
    "df_labels_map = spark.table(f\"{schema_modelos}.label_mapping\")\n",
    "label_mapping_dict = {row['resultado']: row['label'] for row in df_labels_map.collect()}\n",
    "labels_array = [k for k, v in sorted(label_mapping_dict.items(), key=lambda x: x[1])]\n",
    "\n",
    "print(f\"\\n‚úÖ Labels mapeados: {labels_array}\")\n",
    "\n",
    "# Recriar transformadores\n",
    "assembler_meta = VectorAssembler(\n",
    "    inputCols=[\"prob_geral\", \"prob_lr\", \"prob_rf\"],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "converter = IndexToString(\n",
    "    inputCol=\"prediction\",\n",
    "    outputCol=\"previsao_texto\",\n",
    "    labels=labels_array\n",
    ")\n",
    "\n",
    "print(\"  ‚úÖ Transformadores criados\")\n",
    "\n",
    "# Carregar dados auxiliares\n",
    "df_partidas_historico = spark.table(\"gold.feature_store\")\n",
    "df_clubes = spark.table(\"silver.clubes\")\n",
    "\n",
    "print(f\"\\n‚úÖ Dados hist√≥ricos: {df_partidas_historico.count()} partidas\")\n",
    "print(f\"‚úÖ Clubes cadastrados: {df_clubes.count()}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ PASSO 1 CONCLU√çDO - Modelos carregados com sucesso!\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ==============================================================================\n",
    "# DIAGN√ìSTICO: VERIFICAR DADOS DA API\n",
    "# ==============================================================================\n",
    "print(\"\\n[DIAGN√ìSTICO] Verificando integridade dos dados...\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Verificar quantos clubes √∫nicos temos\n",
    "df_clubes_bronze = spark.table(\"bronze.clubes_info_raw\")\n",
    "num_clubes = df_clubes_bronze.count()\n",
    "print(f\"\\nüìä Total de clubes cadastrados: {num_clubes}\")\n",
    "\n",
    "# Verificar se temos 20 times (S√©rie A)\n",
    "if num_clubes != 20:\n",
    "    print(f\"‚ö†Ô∏è ATEN√á√ÉO: Esperado 20 clubes da S√©rie A, encontrado {num_clubes}\")\n",
    "\n",
    "# Mostrar todos os clubes por clube_id\n",
    "print(\"\\nüìã Lista de clubes por ID:\")\n",
    "df_clubes_diagnostico = df_clubes_bronze.select(\n",
    "    F.col(\"id\").alias(\"clube_id\"),\n",
    "    \"nome\",\n",
    "    \"nome_fantasia\",\n",
    "    \"abreviacao\",\n",
    "    \"slug\"\n",
    ").orderBy(\"clube_id\")\n",
    "\n",
    "display(df_clubes_diagnostico)\n",
    "\n",
    "print(\"\\n‚úÖ Diagn√≥stico conclu√≠do\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# ==============================================================================\n",
    "# PASSO 2: CARREGAR PARTIDAS REALIZADAS E CALCULAR TABELA ATUAL\n",
    "# ==============================================================================\n",
    "print(\"\\n[PASSO 2] Calculando classifica√ß√£o atual...\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Partidas j√° realizadas\n",
    "df_partidas_realizadas = spark.table(\"bronze.partidas_raw\") \\\n",
    "    .filter(\"placar_oficial_mandante IS NOT NULL AND valida = true\")\n",
    "\n",
    "# Calcular pontos de cada time\n",
    "df_pontos_mandante = df_partidas_realizadas.select(\n",
    "    F.col(\"clube_casa_id\").alias(\"clube_id\"),\n",
    "    F.when(F.col(\"placar_oficial_mandante\") > F.col(\"placar_oficial_visitante\"), 3)\n",
    "     .when(F.col(\"placar_oficial_mandante\") == F.col(\"placar_oficial_visitante\"), 1)\n",
    "     .otherwise(0).alias(\"pontos\"),\n",
    "    F.col(\"placar_oficial_mandante\").alias(\"gols_marcados\"),\n",
    "    F.col(\"placar_oficial_visitante\").alias(\"gols_sofridos\")\n",
    ")\n",
    "\n",
    "df_pontos_visitante = df_partidas_realizadas.select(\n",
    "    F.col(\"clube_visitante_id\").alias(\"clube_id\"),\n",
    "    F.when(F.col(\"placar_oficial_visitante\") > F.col(\"placar_oficial_mandante\"), 3)\n",
    "     .when(F.col(\"placar_oficial_visitante\") == F.col(\"placar_oficial_mandante\"), 1)\n",
    "     .otherwise(0).alias(\"pontos\"),\n",
    "    F.col(\"placar_oficial_visitante\").alias(\"gols_marcados\"),\n",
    "    F.col(\"placar_oficial_mandante\").alias(\"gols_sofridos\")\n",
    ")\n",
    "\n",
    "df_classificacao_atual = df_pontos_mandante.union(df_pontos_visitante) \\\n",
    "    .groupBy(\"clube_id\") \\\n",
    "    .agg(\n",
    "        F.sum(\"pontos\").alias(\"pontos_atuais\"),\n",
    "        F.count(\"*\").alias(\"jogos_realizados\"),\n",
    "        F.sum(\"gols_marcados\").alias(\"gols_pro\"),\n",
    "        F.sum(\"gols_sofridos\").alias(\"gols_contra\")\n",
    "    ) \\\n",
    "    .withColumn(\"saldo_gols\", F.col(\"gols_pro\") - F.col(\"gols_contra\")) \\\n",
    "    .join(df_clubes, \"clube_id\") \\\n",
    "    .select(\"clube_id\", \"nome\", \"pontos_atuais\", \"jogos_realizados\", \"saldo_gols\")\n",
    "\n",
    "print(\"\\nüìä Classifica√ß√£o Atual:\")\n",
    "display(df_classificacao_atual.orderBy(F.desc(\"pontos_atuais\"), F.desc(\"saldo_gols\")))\n",
    "\n",
    "# ==============================================================================\n",
    "# PASSO 3: CARREGAR E PREPARAR PARTIDAS FUTURAS\n",
    "# ==============================================================================\n",
    "print(\"\\n[PASSO 3] Carregando partidas futuras...\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "df_futuro_raw = spark.table(\"bronze.partidas_raw\") \\\n",
    "    .filter(\"placar_oficial_mandante IS NULL AND valida = true\") \\\n",
    "    .orderBy(\"partida_data\")\n",
    "\n",
    "num_partidas_futuras = df_futuro_raw.count()\n",
    "print(f\"\\nüìã Partidas futuras encontradas: {num_partidas_futuras}\")\n",
    "\n",
    "if num_partidas_futuras == 0:\n",
    "    print(\"\\n‚ö†Ô∏è ATEN√á√ÉO: Nenhuma partida futura encontrada!\")\n",
    "    print(\"\\nüí° Execute o notebook '01_Bronze_Ingestao' para atualizar os dados\")\n",
    "    raise Exception(\"Sem partidas futuras para an√°lise\")\n",
    "\n",
    "print(\"\\n‚úÖ Preview das partidas futuras:\")\n",
    "display(df_futuro_raw.select(\n",
    "    \"partida_id\", \"rodada\", \"partida_data\",\n",
    "    \"clube_casa_id\", \"clube_visitante_id\"\n",
    ").limit(5))\n",
    "\n",
    "# ==============================================================================\n",
    "# PASSO 4: ENGENHARIA DE FEATURES PARA PARTIDAS FUTURAS\n",
    "# ==============================================================================\n",
    "print(\"\\n[PASSO 4] Aplicando engenharia de features...\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Pegar Elo mais recente de cada time\n",
    "latest_elos = df_partidas_historico \\\n",
    "    .groupBy(\"mandante_id\") \\\n",
    "    .agg(F.max(\"rodada\").alias(\"rodada\")) \\\n",
    "    .join(df_partidas_historico, [\"mandante_id\", \"rodada\"]) \\\n",
    "    .select(\"mandante_id\", F.col(\"elo_mandante_pre_jogo\").alias(\"elo_atual\"))\n",
    "\n",
    "# Pegar m√©dias m√≥veis mais recentes\n",
    "latest_mms_m = df_partidas_historico \\\n",
    "    .groupBy(\"mandante_id\") \\\n",
    "    .agg(F.max(\"rodada\").alias(\"rodada\")) \\\n",
    "    .join(df_partidas_historico, [\"mandante_id\", \"rodada\"]) \\\n",
    "    .select(\"mandante_id\", \"mm_gols_m\", \"mm_fin_m\", \"mm_des_m\")\n",
    "\n",
    "latest_mms_v = df_partidas_historico \\\n",
    "    .groupBy(\"visitante_id\") \\\n",
    "    .agg(F.max(\"rodada\").alias(\"rodada\")) \\\n",
    "    .join(df_partidas_historico, [\"visitante_id\", \"rodada\"]) \\\n",
    "    .select(\"visitante_id\", \"mm_gols_v\", \"mm_fin_v\", \"mm_des_v\")\n",
    "\n",
    "# Preparar partidas futuras\n",
    "df_futuro_features = df_futuro_raw.select(\n",
    "    F.col(\"partida_id\"),\n",
    "    F.col(\"rodada\"),\n",
    "    F.col(\"clube_casa_id\").alias(\"mandante_id\"),\n",
    "    F.col(\"clube_visitante_id\").alias(\"visitante_id\"),\n",
    "    F.to_timestamp(\"partida_data\").alias(\"data_partida\")\n",
    ")\n",
    "\n",
    "# Juntar Elo do mandante\n",
    "df_com_elo_m = df_futuro_features.join(\n",
    "    latest_elos,\n",
    "    df_futuro_features[\"mandante_id\"] == latest_elos[\"mandante_id\"],\n",
    "    \"left\"\n",
    ").withColumnRenamed(\"elo_atual\", \"elo_mandante_pre_jogo\") \\\n",
    " .drop(latest_elos[\"mandante_id\"])\n",
    "\n",
    "# Juntar Elo do visitante\n",
    "df_com_elo_mv = df_com_elo_m.join(\n",
    "    latest_elos,\n",
    "    df_com_elo_m[\"visitante_id\"] == latest_elos[\"mandante_id\"],\n",
    "    \"left\"\n",
    ").withColumnRenamed(\"elo_atual\", \"elo_visitante_pre_jogo\") \\\n",
    " .drop(latest_elos[\"mandante_id\"])\n",
    "\n",
    "# Juntar m√©dias m√≥veis do mandante\n",
    "df_com_mm_m = df_com_elo_mv.join(\n",
    "    latest_mms_m,\n",
    "    df_com_elo_mv[\"mandante_id\"] == latest_mms_m[\"mandante_id\"],\n",
    "    \"left\"\n",
    ").drop(latest_mms_m[\"mandante_id\"])\n",
    "\n",
    "# Juntar m√©dias m√≥veis do visitante\n",
    "df_com_tudo = df_com_mm_m.join(\n",
    "    latest_mms_v,\n",
    "    df_com_mm_m[\"visitante_id\"] == latest_mms_v[\"visitante_id\"],\n",
    "    \"left\"\n",
    ").drop(latest_mms_v[\"visitante_id\"])\n",
    "\n",
    "# Calcular diferenciais\n",
    "df_futuro_features_final = df_com_tudo \\\n",
    "    .withColumn(\"elo_diff\", F.col(\"elo_mandante_pre_jogo\") - F.col(\"elo_visitante_pre_jogo\")) \\\n",
    "    .withColumn(\"diff_mm_gols\", F.col(\"mm_gols_m\") - F.col(\"mm_gols_v\")) \\\n",
    "    .withColumn(\"diff_mm_fin\", F.col(\"mm_fin_m\") - F.col(\"mm_fin_v\")) \\\n",
    "    .withColumn(\"diff_mm_des\", F.col(\"mm_des_m\") - F.col(\"mm_des_v\")) \\\n",
    "    .na.fill(0)\n",
    "\n",
    "print(\"  ‚úÖ Features calculadas\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ PASSO 4 CONCLU√çDO - Features prontas!\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ==============================================================================\n",
    "# PASSO 5: FAZER PREVIS√ïES E SIMULAR RESULTADOS\n",
    "# ==============================================================================\n",
    "print(\"\\n[PASSO 5] Gerando previs√µes e simulando resultados...\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# N√≠vel 1: Previs√µes dos especialistas\n",
    "print(\"\\n  N√≠vel 1: Modelos Especialistas...\")\n",
    "pred_geral_futuro = modelo_geral.transform(df_futuro_features_final)\n",
    "pred_lr_futuro = modelo_lr.transform(df_futuro_features_final)\n",
    "pred_rf_futuro = modelo_rf.transform(df_futuro_features_final)\n",
    "print(\"    ‚úÖ Previs√µes dos especialistas geradas\")\n",
    "\n",
    "# Preparar meta-features\n",
    "meta_features_geral = pred_geral_futuro.select(\"partida_id\", F.col(\"probability\").alias(\"prob_geral\"))\n",
    "meta_features_lr = pred_lr_futuro.select(\"partida_id\", F.col(\"probability\").alias(\"prob_lr\"))\n",
    "meta_features_rf = pred_rf_futuro.select(\"partida_id\", F.col(\"probability\").alias(\"prob_rf\"))\n",
    "\n",
    "df_inferencia_meta = df_futuro_features_final.select(\"partida_id\") \\\n",
    "    .join(meta_features_geral, \"partida_id\") \\\n",
    "    .join(meta_features_lr, \"partida_id\") \\\n",
    "    .join(meta_features_rf, \"partida_id\")\n",
    "\n",
    "df_inferencia_meta = assembler_meta.transform(df_inferencia_meta)\n",
    "\n",
    "# N√≠vel 2: Meta-modelo\n",
    "print(\"  N√≠vel 2: Meta-Modelo...\")\n",
    "previsoes_finais = modelo_final.transform(df_inferencia_meta)\n",
    "print(\"    ‚úÖ Previs√µes finais geradas\")\n",
    "\n",
    "# Converter √≠ndices para texto\n",
    "previsoes_texto = converter.transform(previsoes_finais)\n",
    "\n",
    "# ==============================================================================\n",
    "# PASSO 6: AN√ÅLISE AVAN√áADA DE REBAIXAMENTO\n",
    "# ==============================================================================\n",
    "print(\"\\n[PASSO 6] An√°lise de risco de rebaixamento...\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Juntar previs√µes com dados das partidas\n",
    "df_previsoes_completas = df_futuro_features_final \\\n",
    "    .join(previsoes_texto.select(\"partida_id\", \"previsao_texto\", \"probability\"), \"partida_id\")\n",
    "\n",
    "# Importar fun√ß√£o para trabalhar com vetores\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import DoubleType, ArrayType\n",
    "\n",
    "# UDF para converter SparseVector em array denso\n",
    "@udf(returnType=ArrayType(DoubleType()))\n",
    "def vector_to_array(v):\n",
    "    \"\"\"Converte SparseVector/DenseVector para array Python\"\"\"\n",
    "    if v is None:\n",
    "        return [0.0, 0.0, 0.0]\n",
    "    return v.toArray().tolist()\n",
    "\n",
    "# Fun√ß√£o para extrair pontos esperados baseado na probabilidade\n",
    "def calcular_pontos_esperados(df):\n",
    "    \"\"\"\n",
    "    Calcula pontos esperados baseado nas probabilidades do modelo\n",
    "    \n",
    "    Ordem dos labels (definida no notebook 04):\n",
    "    - √çndice 0: EMPATE\n",
    "    - √çndice 1: VITORIA_MANDANTE  \n",
    "    - √çndice 2: VITORIA_VISITANTE\n",
    "    \n",
    "    Pontua√ß√£o:\n",
    "    - VITORIA = 3 pontos\n",
    "    - EMPATE = 1 ponto\n",
    "    - DERROTA = 0 pontos\n",
    "    \"\"\"\n",
    "    # Converter probability (SparseVector) para array\n",
    "    df_com_array = df.withColumn(\"prob_array\", vector_to_array(F.col(\"probability\")))\n",
    "    \n",
    "    return df_com_array.select(\n",
    "        \"partida_id\",\n",
    "        \"mandante_id\",\n",
    "        \"visitante_id\",\n",
    "        \"previsao_texto\",\n",
    "        \"probability\",\n",
    "        \n",
    "        # Extrair probabilidades individuais do array\n",
    "        F.col(\"prob_array\")[0].alias(\"prob_empate\"),\n",
    "        F.col(\"prob_array\")[1].alias(\"prob_vitoria_mandante\"),\n",
    "        F.col(\"prob_array\")[2].alias(\"prob_vitoria_visitante\"),\n",
    "        \n",
    "        # Calcular pontos esperados\n",
    "        # Mandante: (prob_vitoria * 3) + (prob_empate * 1) + (prob_derrota * 0)\n",
    "        (F.col(\"prob_array\")[1] * 3 + F.col(\"prob_array\")[0] * 1).alias(\"pontos_esperados_mandante\"),\n",
    "        # Visitante: (prob_vitoria * 3) + (prob_empate * 1) + (prob_derrota * 0)\n",
    "        (F.col(\"prob_array\")[2] * 3 + F.col(\"prob_array\")[0] * 1).alias(\"pontos_esperados_visitante\")\n",
    "    )\n",
    "\n",
    "df_pontos_esperados = calcular_pontos_esperados(df_previsoes_completas)\n",
    "\n",
    "print(\"\\nüìä Pontos esperados por partida:\")\n",
    "display(df_pontos_esperados.limit(10))\n",
    "\n",
    "# Agregar pontos esperados por time (com aliases para evitar ambiguidade)\n",
    "df_pontos_esperados_mandante = df_pontos_esperados.groupBy(\"mandante_id\") \\\n",
    "    .agg(\n",
    "        F.sum(\"pontos_esperados_mandante\").alias(\"pontos_esperados_m\"),\n",
    "        F.count(\"*\").alias(\"jogos_restantes_m\")\n",
    "    ) \\\n",
    "    .withColumnRenamed(\"mandante_id\", \"clube_id\")\n",
    "\n",
    "df_pontos_esperados_visitante = df_pontos_esperados.groupBy(\"visitante_id\") \\\n",
    "    .agg(\n",
    "        F.sum(\"pontos_esperados_visitante\").alias(\"pontos_esperados_v\"),\n",
    "        F.count(\"*\").alias(\"jogos_restantes_v\")\n",
    "    ) \\\n",
    "    .withColumnRenamed(\"visitante_id\", \"clube_id\")\n",
    "\n",
    "# Combinar pontos de casa e fora (usando aliases para evitar conflito)\n",
    "df_mandante_aliased = df_pontos_esperados_mandante.alias(\"m\")\n",
    "df_visitante_aliased = df_pontos_esperados_visitante.alias(\"v\")\n",
    "\n",
    "df_pontos_totais_esperados = df_mandante_aliased \\\n",
    "    .join(df_visitante_aliased, F.col(\"m.clube_id\") == F.col(\"v.clube_id\"), \"full\") \\\n",
    "    .select(\n",
    "        F.coalesce(F.col(\"m.clube_id\"), F.col(\"v.clube_id\")).alias(\"clube_id\"),\n",
    "        (F.coalesce(F.col(\"m.pontos_esperados_m\"), F.lit(0)) + \n",
    "         F.coalesce(F.col(\"v.pontos_esperados_v\"), F.lit(0))).alias(\"pontos_esperados_total\"),\n",
    "        (F.coalesce(F.col(\"m.jogos_restantes_m\"), F.lit(0)) + \n",
    "         F.coalesce(F.col(\"v.jogos_restantes_v\"), F.lit(0))).alias(\"jogos_restantes_total\")\n",
    "    )\n",
    "\n",
    "# Proje√ß√£o final: pontos atuais + pontos esperados\n",
    "# A tabela df_classificacao_atual j√° tem a coluna \"nome\", ent√£o n√£o precisamos fazer join com clubes novamente\n",
    "df_projecao_final = df_classificacao_atual \\\n",
    "    .join(df_pontos_totais_esperados, \"clube_id\", \"left\") \\\n",
    "    .fillna(0, subset=[\"pontos_esperados_total\", \"jogos_restantes_total\"]) \\\n",
    "    .withColumn(\"pontos_projetados\", F.col(\"pontos_atuais\") + F.col(\"pontos_esperados_total\")) \\\n",
    "    .withColumn(\"total_jogos_campeonato\", F.col(\"jogos_realizados\") + F.col(\"jogos_restantes_total\"))\n",
    "\n",
    "# Calcular for√ßa do calend√°rio (m√©dia do Elo dos advers√°rios)\n",
    "df_adversarios_mandante = df_futuro_features_final \\\n",
    "    .groupBy(\"mandante_id\") \\\n",
    "    .agg(F.avg(\"elo_visitante_pre_jogo\").alias(\"forca_adversarios\")) \\\n",
    "    .withColumnRenamed(\"mandante_id\", \"clube_id\")\n",
    "\n",
    "df_adversarios_visitante = df_futuro_features_final \\\n",
    "    .groupBy(\"visitante_id\") \\\n",
    "    .agg(F.avg(\"elo_mandante_pre_jogo\").alias(\"forca_adversarios\")) \\\n",
    "    .withColumnRenamed(\"visitante_id\", \"clube_id\")\n",
    "\n",
    "df_forca_calendario = df_adversarios_mandante \\\n",
    "    .join(df_adversarios_visitante, \"clube_id\", \"full\") \\\n",
    "    .select(\n",
    "        F.coalesce(df_adversarios_mandante[\"clube_id\"], df_adversarios_visitante[\"clube_id\"]).alias(\"clube_id\"),\n",
    "        ((F.coalesce(df_adversarios_mandante[\"forca_adversarios\"], F.lit(0)) + \n",
    "          F.coalesce(df_adversarios_visitante[\"forca_adversarios\"], F.lit(0))) / 2).alias(\"forca_media_adversarios\")\n",
    "    )\n",
    "\n",
    "# Juntar for√ßa do calend√°rio\n",
    "df_projecao_completa = df_projecao_final \\\n",
    "    .join(df_forca_calendario, \"clube_id\", \"left\") \\\n",
    "    .fillna(0, subset=[\"forca_media_adversarios\"])\n",
    "\n",
    "# Calcular ranking e zona de rebaixamento\n",
    "window_rank = Window.orderBy(F.desc(\"pontos_projetados\"), F.desc(\"saldo_gols\"))\n",
    "\n",
    "df_analise_rebaixamento = df_projecao_completa \\\n",
    "    .withColumn(\"posicao_projetada\", F.row_number().over(window_rank)) \\\n",
    "    .withColumn(\"zona_rebaixamento\", F.when(F.col(\"posicao_projetada\") >= 17, \"SIM\").otherwise(\"N√ÉO\")) \\\n",
    "    .withColumn(\"distancia_z4\", \n",
    "        F.col(\"pontos_projetados\") - F.nth_value(\"pontos_projetados\", 17).over(Window.orderBy(F.desc(\"pontos_projetados\")))\n",
    "    ) \\\n",
    "    .withColumn(\"risco_rebaixamento\",\n",
    "        F.when(F.col(\"posicao_projetada\") >= 17, \"ALTO\")\n",
    "         .when(F.col(\"posicao_projetada\") >= 14, \"M√âDIO\")\n",
    "         .when(F.col(\"posicao_projetada\") >= 11, \"BAIXO\")\n",
    "         .otherwise(\"M√çNIMO\")\n",
    "    )\n",
    "\n",
    "# Adicionar m√©trica de dificuldade do calend√°rio\n",
    "df_analise_final = df_analise_rebaixamento \\\n",
    "    .withColumn(\"dificuldade_calendario\",\n",
    "        F.when(F.col(\"forca_media_adversarios\") > 1520, \"MUITO DIF√çCIL\")\n",
    "         .when(F.col(\"forca_media_adversarios\") > 1480, \"DIF√çCIL\")\n",
    "         .when(F.col(\"forca_media_adversarios\") > 1450, \"M√âDIO\")\n",
    "         .otherwise(\"FAVOR√ÅVEL\")\n",
    "    )\n",
    "\n",
    "# Salvar tabela completa de an√°lise\n",
    "df_analise_final.write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .format(\"delta\") \\\n",
    "    .saveAsTable(\"diamond.analise_rebaixamento\")\n",
    "\n",
    "print(\"\\n‚úÖ An√°lise de rebaixamento salva em 'diamond.analise_rebaixamento'\")\n",
    "\n",
    "# ==============================================================================\n",
    "# VISUALIZA√á√ÉO FINAL - AN√ÅLISE DE REBAIXAMENTO (USANDO CLUBE_ID)\n",
    "# ==============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚ö†Ô∏è AN√ÅLISE DE RISCO DE REBAIXAMENTO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# IMPORTANTE: Trabalhar APENAS com clube_id para evitar confus√£o\n",
    "df_visualizacao = df_analise_final.select(\n",
    "    \"posicao_projetada\",\n",
    "    \"clube_id\",\n",
    "    \"nome\",\n",
    "    \"pontos_atuais\",\n",
    "    \"jogos_realizados\",\n",
    "    \"jogos_restantes_total\",\n",
    "    F.round(\"pontos_esperados_total\", 2).alias(\"pontos_esperados\"),\n",
    "    F.round(\"pontos_projetados\", 2).alias(\"pontos_projetados\"),\n",
    "    \"saldo_gols\",\n",
    "    \"zona_rebaixamento\",\n",
    "    \"risco_rebaixamento\",\n",
    "    \"dificuldade_calendario\",\n",
    "    F.round(\"distancia_z4\", 2).alias(\"distancia_z4\")\n",
    ").orderBy(\"posicao_projetada\")\n",
    "\n",
    "print(\"\\nüìä TABELA DE PROJE√á√ÉO FINAL COM AN√ÅLISE DE REBAIXAMENTO:\")\n",
    "print(\"IMPORTANTE: Use 'clube_id' como refer√™ncia principal, n√£o o nome!\")\n",
    "display(df_visualizacao)\n",
    "\n",
    "# Times em risco\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"üö® TIMES EM ZONA DE REBAIXAMENTO (Posi√ß√µes 17-20):\")\n",
    "print(\"-\"*80)\n",
    "df_zona_rebaixamento = df_visualizacao.filter(\"zona_rebaixamento = 'SIM'\")\n",
    "display(df_zona_rebaixamento)\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"‚ö†Ô∏è TIMES EM SITUA√á√ÉO DE ALERTA (Posi√ß√µes 14-16):\")\n",
    "print(\"-\"*80)\n",
    "df_alerta = df_visualizacao.filter(\"posicao_projetada BETWEEN 14 AND 16\")\n",
    "display(df_alerta)\n",
    "\n",
    "# ==============================================================================\n",
    "# VERIFICA√á√ÉO: MAPA DE CLUBE_ID ‚Üí NOME CORRETO\n",
    "# ==============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üîç VERIFICA√á√ÉO: MAPEAMENTO CLUBE_ID ‚Üí INFORMA√á√ïES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df_mapa_clubes = spark.table(\"silver.clubes\").select(\n",
    "    \"clube_id\",\n",
    "    \"nome\",\n",
    "    \"abreviacao\",\n",
    "    \"nome_completo\"\n",
    ").orderBy(\"clube_id\")\n",
    "\n",
    "print(\"\\nüìã Todos os clubes cadastrados no sistema:\")\n",
    "display(df_mapa_clubes)\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"üéØ CLUBES NA AN√ÅLISE DE REBAIXAMENTO (clube_id):\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Usar aliases para evitar ambiguidade no join\n",
    "df_visualizacao_aliased = df_visualizacao.alias(\"viz\")\n",
    "df_mapa_clubes_aliased = df_mapa_clubes.alias(\"clubes\")\n",
    "\n",
    "df_ids_analise = df_visualizacao_aliased \\\n",
    "    .join(df_mapa_clubes_aliased, F.col(\"viz.clube_id\") == F.col(\"clubes.clube_id\"), \"left\") \\\n",
    "    .select(\n",
    "        F.col(\"viz.clube_id\"),\n",
    "        F.col(\"viz.nome\").alias(\"nome_api\"),\n",
    "        F.col(\"clubes.nome_completo\"),\n",
    "        F.col(\"clubes.abreviacao\"),\n",
    "        F.col(\"viz.posicao_projetada\"),\n",
    "        F.round(F.col(\"viz.pontos_projetados\"), 2).alias(\"pontos_projetados\")\n",
    "    ).orderBy(\"posicao_projetada\")\n",
    "\n",
    "display(df_ids_analise)\n",
    "\n",
    "# Salvar previs√µes das pr√≥ximas partidas tamb√©m\n",
    "df_resultado_final = df_futuro_features_final \\\n",
    "    .join(previsoes_texto.select(\"partida_id\", \"previsao_texto\", \"probability\"), \"partida_id\") \\\n",
    "    .join(df_clubes.alias(\"mandante\"), F.col(\"mandante_id\") == F.col(\"mandante.clube_id\")) \\\n",
    "    .join(df_clubes.alias(\"visitante\"), F.col(\"visitante_id\") == F.col(\"visitante.clube_id\")) \\\n",
    "    .withColumn(\"competicao\", F.lit(\"Brasileir√£o S√©rie A\")) \\\n",
    "    .select(\n",
    "        \"competicao\",\n",
    "        F.date_format(\"data_partida\", \"dd/MM/yyyy HH:mm\").alias(\"data_hora_partida\"),\n",
    "        F.col(\"mandante.nome\").alias(\"time_mandante\"),\n",
    "        F.col(\"visitante.nome\").alias(\"time_visitante\"),\n",
    "        F.col(\"previsao_texto\").alias(\"previsao\"),\n",
    "        F.col(\"probability\").alias(\"confianca_probabilidades\")\n",
    "    ).orderBy(\"data_hora_partida\")\n",
    "\n",
    "df_resultado_final.write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .format(\"delta\") \\\n",
    "    .saveAsTable(\"diamond.previsoes_proximas_partidas\")\n",
    "\n",
    "print(\"\\n‚úÖ Previs√µes das pr√≥ximas partidas salvas em 'diamond.previsoes_proximas_partidas'\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìà M√âTRICAS CHAVE DA AN√ÅLISE (POR CLUBE_ID):\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Calcular algumas estat√≠sticas\n",
    "stats = df_analise_final.select(\n",
    "    F.avg(\"pontos_projetados\").alias(\"media_pontos\"),\n",
    "    F.min(\"pontos_projetados\").alias(\"min_pontos\"),\n",
    "    F.max(\"pontos_projetados\").alias(\"max_pontos\")\n",
    ").collect()[0]\n",
    "\n",
    "linha_corte = df_analise_final.filter(\"posicao_projetada = 17\").select(\"clube_id\", \"pontos_projetados\").collect()\n",
    "if linha_corte:\n",
    "    clube_id_z4 = linha_corte[0][\"clube_id\"]\n",
    "    pontos_z4 = linha_corte[0][\"pontos_projetados\"]\n",
    "    print(f\"\"\"\n",
    "üìä Estat√≠sticas do Campeonato:\n",
    "   ‚Ä¢ M√©dia de pontos projetados: {stats['media_pontos']:.2f}\n",
    "   ‚Ä¢ Menor pontua√ß√£o projetada: {stats['min_pontos']:.2f}\n",
    "   ‚Ä¢ Maior pontua√ß√£o projetada: {stats['max_pontos']:.2f}\n",
    "   ‚Ä¢ Pontos projetados do 17¬∫ colocado (Z4): {pontos_z4:.2f}\n",
    "   ‚Ä¢ Clube ID do 17¬∫ colocado: {clube_id_z4}\n",
    "    \"\"\")\n",
    "\n",
    "# An√°lise detalhada dos times em risco (com clube_id)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üîç AN√ÅLISE DETALHADA - TIMES EM RISCO (clube_id):\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df_analise_risco = df_analise_final.filter(\"posicao_projetada >= 14\") \\\n",
    "    .select(\n",
    "        \"posicao_projetada\",\n",
    "        \"clube_id\",\n",
    "        \"nome\",\n",
    "        \"pontos_atuais\",\n",
    "        \"jogos_restantes_total\",\n",
    "        F.round(\"pontos_esperados_total\", 2).alias(\"pts_esperados\"),\n",
    "        F.round(\"pontos_projetados\", 2).alias(\"pts_projetados\"),\n",
    "        F.round(\"distancia_z4\", 2).alias(\"dist_z4\"),\n",
    "        \"risco_rebaixamento\",\n",
    "        \"dificuldade_calendario\"\n",
    "    ).orderBy(\"posicao_projetada\")\n",
    "\n",
    "display(df_analise_risco)\n",
    "\n",
    "# Analisar pr√≥ximos jogos dos times em risco\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚öΩ PR√ìXIMOS JOGOS DOS TIMES EM RISCO:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Pegar IDs dos times em risco\n",
    "ids_risco = [row[\"clube_id\"] for row in df_analise_risco.collect()]\n",
    "\n",
    "df_jogos_risco = df_futuro_features_final \\\n",
    "    .filter(F.col(\"mandante_id\").isin(ids_risco) | F.col(\"visitante_id\").isin(ids_risco)) \\\n",
    "    .select(\n",
    "        \"rodada\",\n",
    "        \"mandante_id\",\n",
    "        \"visitante_id\",\n",
    "        F.date_format(\"data_partida\", \"dd/MM/yyyy\").alias(\"data\")\n",
    "    ).orderBy(\"rodada\")\n",
    "\n",
    "print(\"\\nPr√≥ximas partidas envolvendo times em risco de rebaixamento:\")\n",
    "display(df_jogos_risco.limit(20))\n",
    "\n",
    "print(\"\\nüí° COMO INTERPRETAR:\")\n",
    "print(\"\"\"\n",
    "1. POSI√á√ÉO PROJETADA: Classifica√ß√£o final estimada baseada nas probabilidades\n",
    "2. PONTOS ESPERADOS: Soma ponderada das probabilidades x pontos poss√≠veis\n",
    "3. DIST√ÇNCIA Z4: Diferen√ßa de pontos para a zona de rebaixamento (negativo = abaixo da linha)\n",
    "4. RISCO DE REBAIXAMENTO: \n",
    "   ‚Ä¢ ALTO: Posi√ß√µes 17-20 (zona de rebaixamento)\n",
    "   ‚Ä¢ M√âDIO: Posi√ß√µes 14-16 (pr√≥ximos √† zona)\n",
    "   ‚Ä¢ BAIXO: Posi√ß√µes 11-13 (ainda com risco matem√°tico)\n",
    "   ‚Ä¢ M√çNIMO: Posi√ß√µes 1-10 (praticamente livres)\n",
    "5. DIFICULDADE DO CALEND√ÅRIO: For√ßa m√©dia dos advers√°rios restantes\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ‚úÖ‚úÖ PIPELINE DE AN√ÅLISE DE REBAIXAMENTO CONCLU√çDO! ‚úÖ‚úÖ‚úÖ\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nüìã CONSULTAS DISPON√çVEIS:\")\n",
    "print(\"   ‚Ä¢ SELECT * FROM diamond.analise_rebaixamento\")\n",
    "print(\"   ‚Ä¢ SELECT * FROM diamond.previsoes_proximas_partidas\")\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "05_Diamond_Inference_Pipeline",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
