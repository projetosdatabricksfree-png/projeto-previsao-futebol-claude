{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "79686acd-71bc-4cb8-ae4e-edaae7221cac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# NOTEBOOK DE INFER√äNCIA - PREVIS√ÉO DE PARTIDAS FUTURAS\n",
    "# ==============================================================================\n",
    "from pyspark.ml import PipelineModel\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.feature import IndexToString, VectorAssembler\n",
    "import mlflow\n",
    "import os\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"PIPELINE DE INFER√äNCIA - PREVIS√ÉO BRASILEIR√ÉO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "spark.sql(\"USE CATALOG previsao_brasileirao\")\n",
    "\n",
    "# ==============================================================================\n",
    "# PASSO 1: CONFIGURAR E CARREGAR MODELOS\n",
    "# ==============================================================================\n",
    "print(\"\\n[PASSO 1] Configurando ambiente e carregando modelos...\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "schema_modelos = \"diamond\"\n",
    "\n",
    "# CONFIGURA√á√ÉO CR√çTICA: Volume path para Databricks Serverless\n",
    "volume_path = \"/Volumes/previsao_brasileirao/diamond/mlflow_models\"\n",
    "os.environ['MLFLOW_DFS_TMP'] = volume_path\n",
    "\n",
    "print(f\"üìÅ Volume configurado: {volume_path}\")\n",
    "\n",
    "# Configurar MLflow\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "# Carregar metadados dos modelos\n",
    "df_modelos_info = spark.table(f\"{schema_modelos}.modelos_registry\") \\\n",
    "    .filter(\"ativo = true\") \\\n",
    "    .orderBy(F.desc(\"versao\"))\n",
    "\n",
    "print(\"\\nüìä Modelos dispon√≠veis:\")\n",
    "display(df_modelos_info.select(\"nome_modelo\", \"tipo\", \"acuracia\", \"run_id\"))\n",
    "\n",
    "# Pegar o run_id mais recente\n",
    "run_id = df_modelos_info.select(\"run_id\").first()[\"run_id\"]\n",
    "print(f\"\\n‚úÖ Usando Run ID: {run_id}\")\n",
    "\n",
    "# Carregar os modelos\n",
    "print(\"\\nCarregando modelos treinados...\")\n",
    "\n",
    "try:\n",
    "    modelo_geral = mlflow.spark.load_model(\n",
    "        f\"runs:/{run_id}/modelo_geral\",\n",
    "        dfs_tmpdir=volume_path\n",
    "    )\n",
    "    print(\"  ‚úÖ Modelo Geral carregado\")\n",
    "    \n",
    "    modelo_lr = mlflow.spark.load_model(\n",
    "        f\"runs:/{run_id}/modelo_lr\",\n",
    "        dfs_tmpdir=volume_path\n",
    "    )\n",
    "    print(\"  ‚úÖ Modelo LR carregado\")\n",
    "    \n",
    "    modelo_rf = mlflow.spark.load_model(\n",
    "        f\"runs:/{run_id}/modelo_rf\",\n",
    "        dfs_tmpdir=volume_path\n",
    "    )\n",
    "    print(\"  ‚úÖ Modelo RF carregado\")\n",
    "    \n",
    "    modelo_final = mlflow.spark.load_model(\n",
    "        f\"runs:/{run_id}/modelo_final\",\n",
    "        dfs_tmpdir=volume_path\n",
    "    )\n",
    "    print(\"  ‚úÖ Meta-Modelo carregado\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå ERRO ao carregar modelos: {e}\")\n",
    "    print(\"\\nüîß Poss√≠veis solu√ß√µes:\")\n",
    "    print(\"1. Verifique se o notebook '04_Diamond_Model_Training' foi executado\")\n",
    "    print(\"2. Execute novamente o PASSO 5 do notebook de treinamento\")\n",
    "    raise\n",
    "\n",
    "# Carregar mapa de labels\n",
    "df_labels_map = spark.table(f\"{schema_modelos}.label_mapping\")\n",
    "label_mapping_dict = {row['resultado']: row['label'] for row in df_labels_map.collect()}\n",
    "labels_array = [k for k, v in sorted(label_mapping_dict.items(), key=lambda x: x[1])]\n",
    "\n",
    "print(f\"\\n‚úÖ Labels mapeados: {labels_array}\")\n",
    "\n",
    "# Recriar transformadores\n",
    "assembler_meta = VectorAssembler(\n",
    "    inputCols=[\"prob_geral\", \"prob_lr\", \"prob_rf\"],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "converter = IndexToString(\n",
    "    inputCol=\"prediction\",\n",
    "    outputCol=\"previsao_texto\",\n",
    "    labels=labels_array\n",
    ")\n",
    "\n",
    "print(\"  ‚úÖ Transformadores criados\")\n",
    "\n",
    "# Carregar dados auxiliares\n",
    "df_partidas_historico = spark.table(\"gold.feature_store\")\n",
    "df_clubes = spark.table(\"silver.clubes\")\n",
    "\n",
    "print(f\"\\n‚úÖ Dados hist√≥ricos: {df_partidas_historico.count()} partidas\")\n",
    "print(f\"‚úÖ Clubes cadastrados: {df_clubes.count()}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ PASSO 1 CONCLU√çDO - Modelos carregados com sucesso!\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ==============================================================================\n",
    "# PASSO 2: CARREGAR E PREPARAR PARTIDAS FUTURAS\n",
    "# ==============================================================================\n",
    "print(\"\\n[PASSO 2] Carregando partidas futuras...\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "df_futuro_raw = spark.table(\"bronze.partidas_raw\") \\\n",
    "    .filter(\"placar_oficial_mandante IS NULL AND valida = true\") \\\n",
    "    .orderBy(\"partida_data\")\n",
    "\n",
    "num_partidas_futuras = df_futuro_raw.count()\n",
    "print(f\"\\nüìã Partidas futuras encontradas: {num_partidas_futuras}\")\n",
    "\n",
    "if num_partidas_futuras == 0:\n",
    "    print(\"\\n‚ö†Ô∏è ATEN√á√ÉO: Nenhuma partida futura encontrada!\")\n",
    "    print(\"\\nüí° Poss√≠veis motivos:\")\n",
    "    print(\"  - A rodada atual j√° foi conclu√≠da\")\n",
    "    print(\"  - A pr√≥xima rodada ainda n√£o foi disponibilizada pela API\")\n",
    "    print(\"\\nüîß Solu√ß√£o:\")\n",
    "    print(\"  Execute o notebook '01_Bronze_Ingestao' para atualizar os dados\")\n",
    "    \n",
    "    # Ainda assim, continuar para mostrar o processo\n",
    "    print(\"\\n  (Continuando com o processo para demonstra√ß√£o...)\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ Preview das partidas futuras:\")\n",
    "    display(df_futuro_raw.select(\n",
    "        \"partida_id\", \"rodada\", \"partida_data\",\n",
    "        \"clube_casa_id\", \"clube_visitante_id\"\n",
    "    ).limit(5))\n",
    "\n",
    "# ==============================================================================\n",
    "# PASSO 3: ENGENHARIA DE FEATURES PARA PARTIDAS FUTURAS\n",
    "# ==============================================================================\n",
    "print(\"\\n[PASSO 3] Aplicando engenharia de features...\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Pegar Elo mais recente de cada time\n",
    "latest_elos = df_partidas_historico \\\n",
    "    .groupBy(\"mandante_id\") \\\n",
    "    .agg(F.max(\"rodada\").alias(\"rodada\")) \\\n",
    "    .join(df_partidas_historico, [\"mandante_id\", \"rodada\"]) \\\n",
    "    .select(\"mandante_id\", F.col(\"elo_mandante_pre_jogo\").alias(\"elo_atual\"))\n",
    "\n",
    "# Pegar m√©dias m√≥veis mais recentes\n",
    "latest_mms_m = df_partidas_historico \\\n",
    "    .groupBy(\"mandante_id\") \\\n",
    "    .agg(F.max(\"rodada\").alias(\"rodada\")) \\\n",
    "    .join(df_partidas_historico, [\"mandante_id\", \"rodada\"]) \\\n",
    "    .select(\"mandante_id\", \"mm_gols_m\", \"mm_fin_m\", \"mm_des_m\")\n",
    "\n",
    "latest_mms_v = df_partidas_historico \\\n",
    "    .groupBy(\"visitante_id\") \\\n",
    "    .agg(F.max(\"rodada\").alias(\"rodada\")) \\\n",
    "    .join(df_partidas_historico, [\"visitante_id\", \"rodada\"]) \\\n",
    "    .select(\"visitante_id\", \"mm_gols_v\", \"mm_fin_v\", \"mm_des_v\")\n",
    "\n",
    "# Preparar partidas futuras\n",
    "df_futuro_features = df_futuro_raw.select(\n",
    "    F.col(\"partida_id\"),\n",
    "    F.col(\"rodada\"),\n",
    "    F.col(\"clube_casa_id\").alias(\"mandante_id\"),\n",
    "    F.col(\"clube_visitante_id\").alias(\"visitante_id\"),\n",
    "    F.to_timestamp(\"partida_data\").alias(\"data_partida\")\n",
    ")\n",
    "\n",
    "# Juntar Elo do mandante\n",
    "df_com_elo_m = df_futuro_features.join(\n",
    "    latest_elos,\n",
    "    df_futuro_features[\"mandante_id\"] == latest_elos[\"mandante_id\"],\n",
    "    \"left\"\n",
    ").withColumnRenamed(\"elo_atual\", \"elo_mandante_pre_jogo\") \\\n",
    " .drop(latest_elos[\"mandante_id\"])\n",
    "\n",
    "# Juntar Elo do visitante\n",
    "df_com_elo_mv = df_com_elo_m.join(\n",
    "    latest_elos,\n",
    "    df_com_elo_m[\"visitante_id\"] == latest_elos[\"mandante_id\"],\n",
    "    \"left\"\n",
    ").withColumnRenamed(\"elo_atual\", \"elo_visitante_pre_jogo\") \\\n",
    " .drop(latest_elos[\"mandante_id\"])\n",
    "\n",
    "# Juntar m√©dias m√≥veis do mandante\n",
    "df_com_mm_m = df_com_elo_mv.join(\n",
    "    latest_mms_m,\n",
    "    df_com_elo_mv[\"mandante_id\"] == latest_mms_m[\"mandante_id\"],\n",
    "    \"left\"\n",
    ").drop(latest_mms_m[\"mandante_id\"])\n",
    "\n",
    "# Juntar m√©dias m√≥veis do visitante\n",
    "df_com_tudo = df_com_mm_m.join(\n",
    "    latest_mms_v,\n",
    "    df_com_mm_m[\"visitante_id\"] == latest_mms_v[\"visitante_id\"],\n",
    "    \"left\"\n",
    ").drop(latest_mms_v[\"visitante_id\"])\n",
    "\n",
    "# Calcular diferenciais\n",
    "df_futuro_features_final = df_com_tudo \\\n",
    "    .withColumn(\"elo_diff\", F.col(\"elo_mandante_pre_jogo\") - F.col(\"elo_visitante_pre_jogo\")) \\\n",
    "    .withColumn(\"diff_mm_gols\", F.col(\"mm_gols_m\") - F.col(\"mm_gols_v\")) \\\n",
    "    .withColumn(\"diff_mm_fin\", F.col(\"mm_fin_m\") - F.col(\"mm_fin_v\")) \\\n",
    "    .withColumn(\"diff_mm_des\", F.col(\"mm_des_m\") - F.col(\"mm_des_v\")) \\\n",
    "    .na.fill(0)\n",
    "\n",
    "print(\"  ‚úÖ Features calculadas\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ PASSO 3 CONCLU√çDO - Features prontas!\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ==============================================================================\n",
    "# PASSO 4: FAZER PREVIS√ïES\n",
    "# ==============================================================================\n",
    "print(\"\\n[PASSO 4] Gerando previs√µes...\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "if num_partidas_futuras > 0:\n",
    "    # N√≠vel 1: Previs√µes dos especialistas\n",
    "    print(\"\\n  N√≠vel 1: Modelos Especialistas...\")\n",
    "    pred_geral_futuro = modelo_geral.transform(df_futuro_features_final)\n",
    "    pred_lr_futuro = modelo_lr.transform(df_futuro_features_final)\n",
    "    pred_rf_futuro = modelo_rf.transform(df_futuro_features_final)\n",
    "    print(\"    ‚úÖ Previs√µes dos especialistas geradas\")\n",
    "    \n",
    "    # Preparar meta-features\n",
    "    meta_features_geral = pred_geral_futuro.select(\"partida_id\", F.col(\"probability\").alias(\"prob_geral\"))\n",
    "    meta_features_lr = pred_lr_futuro.select(\"partida_id\", F.col(\"probability\").alias(\"prob_lr\"))\n",
    "    meta_features_rf = pred_rf_futuro.select(\"partida_id\", F.col(\"probability\").alias(\"prob_rf\"))\n",
    "    \n",
    "    df_inferencia_meta = df_futuro_features_final.select(\"partida_id\") \\\n",
    "        .join(meta_features_geral, \"partida_id\") \\\n",
    "        .join(meta_features_lr, \"partida_id\") \\\n",
    "        .join(meta_features_rf, \"partida_id\")\n",
    "    \n",
    "    df_inferencia_meta = assembler_meta.transform(df_inferencia_meta)\n",
    "    \n",
    "    # N√≠vel 2: Meta-modelo\n",
    "    print(\"  N√≠vel 2: Meta-Modelo...\")\n",
    "    previsoes_finais = modelo_final.transform(df_inferencia_meta)\n",
    "    print(\"    ‚úÖ Previs√µes finais geradas\")\n",
    "    \n",
    "    # Converter √≠ndices para texto\n",
    "    previsoes_texto = converter.transform(previsoes_finais)\n",
    "    \n",
    "    # Juntar com nomes dos clubes\n",
    "    df_resultado_final = df_futuro_features_final \\\n",
    "        .join(previsoes_texto.select(\"partida_id\", \"previsao_texto\", \"probability\"), \"partida_id\") \\\n",
    "        .join(df_clubes.alias(\"mandante\"), F.col(\"mandante_id\") == F.col(\"mandante.clube_id\")) \\\n",
    "        .join(df_clubes.alias(\"visitante\"), F.col(\"visitante_id\") == F.col(\"visitante.clube_id\")) \\\n",
    "        .withColumn(\"competicao\", F.lit(\"Brasileir√£o S√©rie A\")) \\\n",
    "        .select(\n",
    "            \"competicao\",\n",
    "            F.date_format(\"data_partida\", \"dd/MM/yyyy HH:mm\").alias(\"data_hora_partida\"),\n",
    "            F.col(\"mandante.nome\").alias(\"time_mandante\"),\n",
    "            F.col(\"visitante.nome\").alias(\"time_visitante\"),\n",
    "            F.col(\"previsao_texto\").alias(\"previsao\"),\n",
    "            F.col(\"probability\").alias(\"confianca_probabilidades\")\n",
    "        ).orderBy(\"data_hora_partida\")\n",
    "    \n",
    "    # Salvar na camada Diamond\n",
    "    df_resultado_final.write \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .format(\"delta\") \\\n",
    "        .saveAsTable(\"diamond.previsoes_proximas_partidas\")\n",
    "    \n",
    "    print(\"\\n  ‚úÖ Previs√µes salvas em 'diamond.previsoes_proximas_partidas'\")\n",
    "    \n",
    "    # Criar view tempor√°ria\n",
    "    df_resultado_final.createOrReplaceTempView(\"visualizacao_previsoes\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"‚úÖ PASSO 4 CONCLU√çDO - Previs√µes geradas!\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # ==============================================================================\n",
    "    # VISUALIZA√á√ÉO FINAL\n",
    "    # ==============================================================================\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìä PREVIS√ïES DAS PR√ìXIMAS PARTIDAS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    display(df_resultado_final)\n",
    "    \n",
    "    print(\"\\n‚úÖ Voc√™ pode consultar as previs√µes usando:\")\n",
    "    print(\"   SELECT * FROM diamond.previsoes_proximas_partidas\")\n",
    "    print(\"   ou\")\n",
    "    print(\"   SELECT * FROM visualizacao_previsoes\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Nenhuma previs√£o gerada pois n√£o h√° partidas futuras\")\n",
    "    print(\"   Execute o notebook '01_Bronze_Ingestao' e tente novamente\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ‚úÖ‚úÖ PIPELINE DE INFER√äNCIA CONCLU√çDO! ‚úÖ‚úÖ‚úÖ\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "05_Diamond_Inference_Pipeline",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
