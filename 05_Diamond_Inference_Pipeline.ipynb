{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fcd94660-558a-4384-aa28-e9e75334be18",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# PASSO 1: CARREGAR MODELOS TREINADOS E DADOS DAS PRÓXIMAS PARTIDAS\n",
    "# ==============================================================================\n",
    "from pyspark.ml import PipelineModel\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.feature import IndexToString, VectorAssembler\n",
    "import mlflow\n",
    "\n",
    "spark.sql(\"USE CATALOG previsao_brasileirao\")\n",
    "\n",
    "# --- AJUSTE APLICADO: CARREGANDO MODELOS DO UNITY CATALOG POR ALIAS ---\n",
    "print(\"Carregando modelos do Unity Catalog Model Registry usando o alias '@Champion'...\")\n",
    "\n",
    "# O nome completo de um modelo no UC é <catalogo>.<schema>.<nome>\n",
    "schema_modelos = \"diamond\"\n",
    "\n",
    "# A sintaxe agora é \"models:/<nome_completo>@<alias>\"\n",
    "modelo_geral = mlflow.spark.load_model(f\"models:/previsao_brasileirao.{schema_modelos}.modelo_geral@Champion\")\n",
    "modelo_lr = mlflow.spark.load_model(f\"models:/previsao_brasileirao.{schema_modelos}.modelo_lr@Champion\")\n",
    "modelo_rf = mlflow.spark.load_model(f\"models:/previsao_brasileirao.{schema_modelos}.modelo_rf@Champion\")\n",
    "modelo_final = mlflow.spark.load_model(f\"models:/previsao_brasileirao.{schema_modelos}.modelo_final@Champion\")\n",
    "label_indexer_model = mlflow.spark.load_model(f\"models:/previsao_brasileirao.{schema_modelos}.label_indexer_model@Champion\")\n",
    "\n",
    "print(\"  ✅ Modelos carregados com sucesso.\")\n",
    "# --- FIM DO AJUSTE ---\n",
    "\n",
    "# Recriar o assembler_meta, pois ele é apenas uma definição de stage\n",
    "assembler_meta = VectorAssembler(inputCols=[\"prob_geral\", \"prob_lr\", \"prob_rf\"], outputCol=\"features\")\n",
    "\n",
    "# Carregar dados das partidas\n",
    "df_futuro_raw = spark.table(\"bronze.partidas_raw\") \\\n",
    "    .filter(\"placar_oficial_mandante IS NULL AND valida = true\") \\\n",
    "    .orderBy(\"partida_data\")\n",
    "\n",
    "df_partidas_historico = spark.table(\"gold.feature_store\")\n",
    "df_clubes = spark.table(\"silver.clubes\")\n",
    "\n",
    "print(f\"Encontradas {df_futuro_raw.count()} partidas futuras para prever.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eecab0a6-0de4-4450-85b7-d3f3643933f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# PASSO 2: APLICAR A ENGENHARIA DE FEATURES NAS PARTIDAS FUTURAS\n",
    "# ==============================================================================\n",
    "print(\"Iniciando a engenharia de features para dados futuros...\")\n",
    "\n",
    "# Pegar o Elo mais recente de cada time do nosso histórico\n",
    "latest_elos = df_partidas_historico \\\n",
    "    .groupBy(\"mandante_id\") \\\n",
    "    .agg(F.max(\"rodada\").alias(\"rodada\")) \\\n",
    "    .join(df_partidas_historico, [\"mandante_id\", \"rodada\"]) \\\n",
    "    .select(\"mandante_id\", F.col(\"elo_mandante_pre_jogo\").alias(\"elo_atual\"))\n",
    "\n",
    "# Pegar as médias móveis mais recentes de cada time\n",
    "latest_mms_m = df_partidas_historico.groupBy(\"mandante_id\").agg(F.max(\"rodada\").alias(\"rodada\")).join(df_partidas_historico, [\"mandante_id\", \"rodada\"]).select(\"mandante_id\", \"mm_gols_m\", \"mm_fin_m\", \"mm_des_m\")\n",
    "latest_mms_v = df_partidas_historico.groupBy(\"visitante_id\").agg(F.max(\"rodada\").alias(\"rodada\")).join(df_partidas_historico, [\"visitante_id\", \"rodada\"]).select(\"visitante_id\", \"mm_gols_v\", \"mm_fin_v\", \"mm_des_v\")\n",
    "\n",
    "# Preparar as partidas futuras\n",
    "df_futuro_features = df_futuro_raw.select(\n",
    "    F.col(\"partida_id\"),\n",
    "    F.col(\"rodada\"),\n",
    "    F.col(\"clube_casa_id\").alias(\"mandante_id\"),\n",
    "    F.col(\"clube_visitante_id\").alias(\"visitante_id\"),\n",
    "    F.to_timestamp(\"partida_data\").alias(\"data_partida\")\n",
    ")\n",
    "\n",
    "# --- AJUSTES APLICADOS AQUI ---\n",
    "\n",
    "# Juntar ELO do mandante\n",
    "df_futuro_com_elo_m = df_futuro_features.join(\n",
    "    latest_elos,\n",
    "    df_futuro_features[\"mandante_id\"] == latest_elos[\"mandante_id\"], # Notação de colchetes\n",
    "    \"left\"\n",
    ").withColumnRenamed(\"elo_atual\", \"elo_mandante_pre_jogo\").drop(latest_elos[\"mandante_id\"]) # Drop explícito\n",
    "\n",
    "# Juntar ELO do visitante\n",
    "df_futuro_com_elo_mv = df_futuro_com_elo_m.join(\n",
    "    latest_elos,\n",
    "    df_futuro_com_elo_m[\"visitante_id\"] == latest_elos[\"mandante_id\"], # Notação de colchetes\n",
    "    \"left\"\n",
    ").withColumnRenamed(\"elo_atual\", \"elo_visitante_pre_jogo\").drop(latest_elos[\"mandante_id\"]) # Drop explícito\n",
    "\n",
    "# Juntar MMs do mandante\n",
    "df_com_mm_m = df_futuro_com_elo_mv.join(\n",
    "    latest_mms_m,\n",
    "    df_futuro_com_elo_mv[\"mandante_id\"] == latest_mms_m[\"mandante_id\"], # Notação de colchetes\n",
    "    \"left\"\n",
    ").drop(latest_mms_m[\"mandante_id\"]) # Drop explícito\n",
    "\n",
    "# Juntar MMs do visitante\n",
    "df_com_tudo = df_com_mm_m.join(\n",
    "    latest_mms_v,\n",
    "    df_com_mm_m[\"visitante_id\"] == latest_mms_v[\"visitante_id\"], # Notação de colchetes\n",
    "    \"left\"\n",
    ").drop(latest_mms_v[\"visitante_id\"]) # Drop explícito\n",
    "\n",
    "\n",
    "# Calcular diferenciais no DataFrame final\n",
    "df_final_features = df_com_tudo.withColumn(\"elo_diff\", F.col(\"elo_mandante_pre_jogo\") - F.col(\"elo_visitante_pre_jogo\")) \\\n",
    "                               .withColumn(\"diff_mm_gols\", F.col(\"mm_gols_m\") - F.col(\"mm_gols_v\")) \\\n",
    "                               .withColumn(\"diff_mm_fin\", F.col(\"mm_fin_m\") - F.col(\"mm_fin_v\")) \\\n",
    "                               .withColumn(\"diff_mm_des\", F.col(\"mm_des_m\") - F.col(\"mm_des_v\")) \\\n",
    "                               .na.fill(0)\n",
    "\n",
    "print(\"Engenharia de features para dados futuros concluída.\")\n",
    "# Atribuir o resultado final à variável que o próximo passo usará\n",
    "df_futuro_features = df_final_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7644bd8b-5f25-4544-97c6-7bf9c669e622",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# PASSO 3: FAZER AS PREVISÕES E FORMATAR A SAÍDA\n",
    "# ==============================================================================\n",
    "# Nível 1: Gerar previsões dos especialistas\n",
    "pred_geral_futuro = modelo_geral.transform(df_futuro_features)\n",
    "pred_lr_futuro = modelo_lr.transform(df_futuro_features)\n",
    "pred_rf_futuro = modelo_rf.transform(df_futuro_features)\n",
    "\n",
    "# Preparar as meta-features para o Nível 2\n",
    "meta_features_geral = pred_geral_futuro.select(\"partida_id\", F.col(\"probability\").alias(\"prob_geral\"))\n",
    "meta_features_lr = pred_lr_futuro.select(\"partida_id\", F.col(\"probability\").alias(\"prob_lr\"))\n",
    "meta_features_rf = pred_rf_futuro.select(\"partida_id\", F.col(\"probability\").alias(\"prob_rf\"))\n",
    "\n",
    "df_inferencia_meta = df_futuro_features.select(\"partida_id\") \\\n",
    "    .join(meta_features_geral, \"partida_id\") \\\n",
    "    .join(meta_features_lr, \"partida_id\") \\\n",
    "    .join(meta_features_rf, \"partida_id\")\n",
    "\n",
    "df_inferencia_meta = assembler_meta.transform(df_inferencia_meta) # Reusa o 'assembler_meta' do notebook de treino\n",
    "\n",
    "# Nível 2: Fazer a previsão final com o Meta-Modelo\n",
    "previsoes_finais = modelo_final.transform(df_inferencia_meta)\n",
    "\n",
    "# Converter o índice numérico da previsão de volta para texto (V/E/D)\n",
    "converter = IndexToString(inputCol=\"prediction\", outputCol=\"previsao_texto\", labels=label_indexer.labels)\n",
    "previsoes_texto = converter.transform(previsoes_finais)\n",
    "\n",
    "# Juntar com os nomes dos clubes para a visualização final\n",
    "df_resultado_final = df_futuro_features \\\n",
    "    .join(previsoes_texto.select(\"partida_id\", \"previsao_texto\", \"probability\"), \"partida_id\") \\\n",
    "    .join(df_clubes.alias(\"mandante\"), F.col(\"mandante_id\") == F.col(\"mandante.clube_id\")) \\\n",
    "    .join(df_clubes.alias(\"visitante\"), F.col(\"visitante_id\") == F.col(\"visitante.clube_id\")) \\\n",
    "    .withColumn(\"competicao\", F.lit(\"Brasileirão Série A\")) \\\n",
    "    .select(\n",
    "        \"competicao\",\n",
    "        F.date_format(\"data_partida\", \"dd/MM/yyyy HH:mm\").alias(\"data_hora_partida\"),\n",
    "        F.col(\"mandante.nome\").alias(\"time_mandante\"),\n",
    "        F.col(\"visitante.nome\").alias(\"time_visitante\"),\n",
    "        F.col(\"previsao_texto\").alias(\"previsao\"),\n",
    "        F.col(\"probability\").alias(\"confianca_probabilidades\")\n",
    "    ).orderBy(\"data_hora_partida\")\n",
    "\n",
    "# Salvar o resultado na Camada Diamond para consulta\n",
    "df_resultado_final.write.mode(\"overwrite\").format(\"delta\").saveAsTable(\"diamond.previsoes_proximas_partidas\")\n",
    "\n",
    "print(\"Previsões geradas com sucesso!\")\n",
    "# Criar uma view temporária para facilitar a consulta via SQL\n",
    "df_resultado_final.createOrReplaceTempView(\"visualizacao_previsoes\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "05_Diamond_Inference_Pipeline",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
