{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "74607f40-cda3-4472-8e6e-888451bf089c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# DIAGN√ìSTICO: VERIFICAR ESTADO DOS MODELOS NO UNITY CATALOG\n",
    "# ==============================================================================\n",
    "import mlflow\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"DIAGN√ìSTICO DO UNITY CATALOG MODEL REGISTRY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Configurar Unity Catalog\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "\n",
    "catalog = \"previsao_brasileirao\"\n",
    "schema = \"diamond\"\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. VERIFICAR SE O SCHEMA EXISTE\n",
    "# ==============================================================================\n",
    "print(\"\\n[1] Verificando estrutura do cat√°logo...\")\n",
    "\n",
    "try:\n",
    "    schemas = spark.sql(f\"SHOW SCHEMAS IN {catalog}\").collect()\n",
    "    print(f\"‚úÖ Schemas encontrados em '{catalog}':\")\n",
    "    for s in schemas:\n",
    "        print(f\"   - {s.databaseName}\")\n",
    "    \n",
    "    if any(s.databaseName == schema for s in schemas):\n",
    "        print(f\"\\n‚úÖ Schema '{schema}' existe!\")\n",
    "    else:\n",
    "        print(f\"\\n‚ùå Schema '{schema}' N√ÉO encontrado!\")\n",
    "        print(f\"\\nCriando schema '{schema}'...\")\n",
    "        spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {catalog}.{schema}\")\n",
    "        print(f\"‚úÖ Schema '{schema}' criado!\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro ao verificar schemas: {e}\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. LISTAR TODOS OS MODELOS REGISTRADOS\n",
    "# ==============================================================================\n",
    "print(f\"\\n[2] Listando modelos em '{catalog}.{schema}'...\")\n",
    "\n",
    "try:\n",
    "    # Tentar listar modelos usando MLflow\n",
    "    all_models = client.search_registered_models(\n",
    "        filter_string=f\"name LIKE '{catalog}.{schema}.%'\"\n",
    "    )\n",
    "    \n",
    "    if all_models:\n",
    "        print(f\"‚úÖ Modelos encontrados: {len(all_models)}\")\n",
    "        for model in all_models:\n",
    "            print(f\"\\nüì¶ {model.name}\")\n",
    "            # Listar vers√µes\n",
    "            versions = client.search_model_versions(f\"name='{model.name}'\")\n",
    "            for v in versions:\n",
    "                print(f\"   - Vers√£o {v.version}: {v.current_stage}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Nenhum modelo encontrado no registro do Unity Catalog\")\n",
    "        print(\"\\nIsso significa que voc√™ precisa:\")\n",
    "        print(\"1. Executar o notebook '04_Diamond_Model_Training_and_Evaluation'\")\n",
    "        print(\"2. Especificamente o PASSO 5 (salvar modelos)\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro ao listar modelos: {e}\")\n",
    "    print(f\"\\nDetalhes: {type(e).__name__}\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. VERIFICAR TABELAS EXISTENTES NO SCHEMA\n",
    "# ==============================================================================\n",
    "print(f\"\\n[3] Verificando tabelas em '{catalog}.{schema}'...\")\n",
    "\n",
    "try:\n",
    "    tables = spark.sql(f\"SHOW TABLES IN {catalog}.{schema}\").collect()\n",
    "    \n",
    "    if tables:\n",
    "        print(f\"‚úÖ Tabelas encontradas: {len(tables)}\")\n",
    "        for t in tables:\n",
    "            table_name = t.tableName\n",
    "            count = spark.table(f\"{catalog}.{schema}.{table_name}\").count()\n",
    "            print(f\"   - {table_name}: {count:,} registros\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Nenhuma tabela encontrada no schema\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro ao listar tabelas: {e}\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. VERIFICAR EXPERIMENTOS MLFLOW\n",
    "# ==============================================================================\n",
    "print(\"\\n[4] Verificando experimentos MLflow...\")\n",
    "\n",
    "try:\n",
    "    experiments = mlflow.search_experiments()\n",
    "    \n",
    "    if experiments:\n",
    "        print(f\"‚úÖ Experimentos encontrados: {len(experiments)}\")\n",
    "        for exp in experiments:\n",
    "            print(f\"   - {exp.name} (ID: {exp.experiment_id})\")\n",
    "            \n",
    "            # Listar runs do experimento\n",
    "            runs = mlflow.search_runs(experiment_ids=[exp.experiment_id], max_results=5)\n",
    "            if not runs.empty:\n",
    "                print(f\"     Runs: {len(runs)}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Nenhum experimento encontrado\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro ao listar experimentos: {e}\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 5. VERIFICAR VARI√ÅVEIS DE TREINAMENTO\n",
    "# ==============================================================================\n",
    "print(\"\\n[5] Verificando vari√°veis do notebook de treinamento...\")\n",
    "\n",
    "variaveis_esperadas = [\n",
    "    'modelo_geral',\n",
    "    'modelo_lr',\n",
    "    'modelo_rf',\n",
    "    'modelo_final',\n",
    "    'df_labels_map'\n",
    "]\n",
    "\n",
    "for var in variaveis_esperadas:\n",
    "    if var in dir():\n",
    "        print(f\"‚úÖ Vari√°vel '{var}' existe na mem√≥ria\")\n",
    "    else:\n",
    "        print(f\"‚ùå Vari√°vel '{var}' N√ÉO existe na mem√≥ria\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESUMO DO DIAGN√ìSTICO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nüîç PR√ìXIMOS PASSOS:\")\n",
    "print(\"\\nSe NENHUM modelo foi encontrado:\")\n",
    "print(\"  1. Execute TODO o notebook '04_Diamond_Model_Training_and_Evaluation'\")\n",
    "print(\"  2. N√£o pule nenhuma c√©lula\")\n",
    "print(\"  3. Aguarde cada c√©lula terminar antes de executar a pr√≥xima\")\n",
    "print(\"\\nSe os modelos foram encontrados mas n√£o podem ser carregados:\")\n",
    "print(\"  1. Verifique os aliases com: client.get_model_version_by_alias()\")\n",
    "print(\"  2. Tente carregar pela vers√£o: 'models:/.../modelo/1'\")\n",
    "print(\"\\nSe o schema n√£o existe:\")\n",
    "print(\"  1. Execute: spark.sql('CREATE SCHEMA IF NOT EXISTS previsao_brasileirao.diamond')\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Untitled Notebook 2025-10-17 15_18_10",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
